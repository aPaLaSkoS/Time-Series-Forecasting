{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","collapsed_sections":["mnqvk5BO_Qh8","ene0f0Uz_SYb","5VrJ6nvMbK8w","04ysdCZGbG_H","xF7JUjfxbfyE","eIVX98nwON0c"],"toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyMHKQ9igRelcUZ8cMtsnXK7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"3e7fd7632c274b46b559edb4930d5860":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a113dc9999e34cb3b969fbce9aeb5075","IPY_MODEL_e8ad0d0e9b1c4659bc98a57bb667394c","IPY_MODEL_20c6ab3f21cd4a21a54246fbf24bf9cd"],"layout":"IPY_MODEL_e5a1a2d2b51c4c089f7f8706c044420c"}},"a113dc9999e34cb3b969fbce9aeb5075":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6c1e8097156442a69e74c6bd90e22709","placeholder":"​","style":"IPY_MODEL_11bcb41b799a408baf5dd7ec2cf4c464","value":"  5%"}},"e8ad0d0e9b1c4659bc98a57bb667394c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bf43df710134212adfc8cbe11002ff7","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_642107b41a0a4b1d8cfb7628a9f0c720","value":48}},"20c6ab3f21cd4a21a54246fbf24bf9cd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e486d7e424b643bc8e304fa0b3366a40","placeholder":"​","style":"IPY_MODEL_4efe0870baf0410aa0f0885398c84973","value":" 48/1000 [07:02&lt;2:16:51,  8.63s/it]"}},"e5a1a2d2b51c4c089f7f8706c044420c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c1e8097156442a69e74c6bd90e22709":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"11bcb41b799a408baf5dd7ec2cf4c464":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bf43df710134212adfc8cbe11002ff7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"642107b41a0a4b1d8cfb7628a9f0c720":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e486d7e424b643bc8e304fa0b3366a40":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4efe0870baf0410aa0f0885398c84973":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ueHGkcxOOpF3","executionInfo":{"status":"ok","timestamp":1684945012241,"user_tz":-180,"elapsed":5308,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"5ec2eb60-29cc-4ecd-c048-bec388e54e2b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.4\n"]}]},{"cell_type":"markdown","source":["# Imports"],"metadata":{"id":"mnqvk5BO_Qh8"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"-aAf6BX89Tvo","executionInfo":{"status":"ok","timestamp":1684945018155,"user_tz":-180,"elapsed":5920,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"outputs":[],"source":["import math\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","\n","from google.colab import files\n","from tqdm.auto import tqdm\n","from torchmetrics import MeanAbsolutePercentageError\n","from datetime import datetime  "]},{"cell_type":"markdown","source":["# Classes + Helpers"],"metadata":{"id":"ene0f0Uz_SYb"}},{"cell_type":"markdown","source":["## Data processing"],"metadata":{"id":"5VrJ6nvMbK8w"}},{"cell_type":"code","source":["def scale_data(load_df, \n","               start_train_date,\n","               end_val_date,\n","               start_test_date,\n","               end_test_date):\n","  \n","  train_val_df = load_df[(load_df.index >= start_train_date) &\n","                        (load_df.index <= end_val_date)]\n","  test_df = load_df[(load_df.index >= start_test_date) &\n","                    (load_df.index <= end_test_date)]\n","\n","  scaler = MinMaxScaler()\n","  train_val_scaled = scaler.fit_transform(train_val_df)\n","  train_val_df_scaled = pd.DataFrame(train_val_scaled,\n","                                    columns=train_val_df.columns,\n","                                    index=train_val_df.index)\n","  test_scaled = scaler.transform(test_df)\n","  test_df_scaled = pd.DataFrame(test_scaled,\n","                                columns=test_df.columns,\n","                                index=test_df.index)\n","\n","  load_df_scaled = pd.concat([train_val_df_scaled, test_df_scaled], axis=0)\n","\n","  return load_df_scaled, scaler"],"metadata":{"id":"20DCtZ_EJ8ti","executionInfo":{"status":"ok","timestamp":1684946176936,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def reframing(X_df, Y_df, n_backwards=1, skip_steps_forward=0, n_forwards=1):\n","\n","  feat_cols, feat_names = [], []\n","  # iterate through all columns\n","  for col_index, col_name in enumerate(X_df.columns):\n","    series = X_df[col_name].copy()\n","    # input sequence (t, t-1, ... ,t-(n_backwards+1) )\n","    for b in range(n_backwards):\n","      feat_cols.append(series.shift(b))\n","      feat_names.append(f'{col_name}_(t-{b})')\n","  \n","  # put it all together\n","  X = pd.concat(feat_cols, axis=1)\n","  X.columns = feat_names\n","  # drop rows with NaN values\n","  X.dropna(inplace=True)\n","  X_index = X.index\n","    \n","  # forecast sequence (t + SKIP_STEPS_FORWARD + 1, ... , t + n_forwards)\n","  series = Y_df\n","  target_cols, target_names = [], []\n","  for f in range(skip_steps_forward + 1, n_forwards): \n","    target_cols.append(Y_df.shift(-f))\n","    if f == 0:\n","      target_names.append(f'{Y_df.name}_t')\n","    else:\n","      target_names.append(f'{Y_df.name}_(t+{f})')\n","\n","  # put it all together\n","  Y = pd.concat(target_cols, axis=1)\n","  Y.columns = target_names\n","  # drop rows with NaN values\n","  Y.dropna(inplace=True)\n","  Y_index = Y.index\n","  \n","  return X, X_index, Y, Y_index\n","\n","\n","def reframe_data(load_df_scaled, \n","                 target,\n","                 days_back,\n","                 last_step_forward,\n","                 last_step_back,\n","                 skip_steps_forward):\n","\n","  time_weather_cols = load_df_scaled.drop(TARGET, axis=1).columns\n","\n","  # shift future values\n","  for col in time_weather_cols:\n","    load_df_scaled[col + f'_(t+{LAST_STEP_FORWARD})'] = load_df_scaled[col].shift(-LAST_STEP_FORWARD)\n","    load_df_scaled.drop(col, axis=1, inplace=True)\n","\n","  X_orig, X_index, Y_orig, Y_index = reframing(load_df_scaled, \n","                                                load_df_scaled[TARGET], \n","                                                n_backwards=LAST_STEP_BACK,\n","                                                skip_steps_forward=SKIP_STEPS_FORWARD,\n","                                                n_forwards=LAST_STEP_FORWARD+1)\n","  common_index = X_index.intersection(Y_index)\n","  X_df = X_orig.loc[common_index]\n","  Y_df = Y_orig.loc[common_index]\n","\n","  load_df_scaled_reframed = pd.concat([X_df, Y_df], axis=1)\n","\n","  return load_df_scaled_reframed"],"metadata":{"id":"lh1YUHYrKTEQ","executionInfo":{"status":"ok","timestamp":1684946176936,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["def create3Dinput(df, last_step_back):\n","  N, D = df.shape\n","  D = int(D/last_step_back)\n","  arr_3d = np.zeros((N, last_step_back, D))\n","  for i in range(D):\n","    arr_3d[:, :, i] = df.iloc[:, i*last_step_back:(i+1)*last_step_back].values\n","  print(arr_3d.shape)\n","  return arr_3d\n","\n","\n","def split_data(load_df_scaled_reframed,\n","               start_train_date,\n","               end_train_date,\n","               start_val_date,\n","               end_val_date,\n","               start_test_date,\n","               end_test_date,\n","               steps_forward,\n","               last_step_back):\n","\n","  load_train_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_train_date) & \n","                                                          (load_df_scaled_reframed.index <= end_train_date)]\n","\n","  load_val_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_val_date) & \n","                                                        (load_df_scaled_reframed.index <= end_val_date)]\n","\n","  load_test_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_test_date) & \n","                                                        (load_df_scaled_reframed.index <= end_test_date)]\n","\n","  load_train_df_scaled_reframed = shuffle(load_train_df_scaled_reframed)    \n","\n","  X_train_df = load_train_df_scaled_reframed.iloc[:, :-steps_forward]\n","  y_train_df = load_train_df_scaled_reframed.iloc[:, -steps_forward:]\n","\n","  X_val_df = load_val_df_scaled_reframed.iloc[:, :-steps_forward]\n","  y_val_df = load_val_df_scaled_reframed.iloc[:, -steps_forward:]\n","\n","  X_test_df = load_test_df_scaled_reframed.iloc[:, :-steps_forward]\n","  y_test_df = load_test_df_scaled_reframed.iloc[:, -steps_forward:]\n","\n","  X_train_3D = create3Dinput(X_train_df, last_step_back)\n","  X_val_3D = create3Dinput(X_val_df, last_step_back)\n","  X_test_3D = create3Dinput(X_test_df, last_step_back)\n","\n","  return X_train_3D, X_val_3D, X_test_3D, y_train_df, y_val_df, y_test_df"],"metadata":{"id":"V-8n4sGJKgGw","executionInfo":{"status":"ok","timestamp":1684946176937,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class LoadDataset(Dataset):\n","  def __init__(self, X_3D, y_df):\n","    self.X = torch.tensor(X_3D, dtype=torch.float32)\n","    self.y = torch.tensor(y_df.values, dtype=torch.float32)\n","  \n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self, idx):\n","    return self.X[idx], self.y[idx]"],"metadata":{"id":"YHTGg8XFOmJq","executionInfo":{"status":"ok","timestamp":1684946176937,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Transformer - Encoder"],"metadata":{"id":"04ysdCZGbG_H"}},{"cell_type":"code","source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, d_k, d_model, n_heads):\n","    super().__init__()\n","\n","    # Assume d_v = d_k\n","    self.d_k = d_k\n","    self.n_heads = n_heads\n","\n","    self.key = nn.Linear(d_model, d_k * n_heads)\n","    self.query = nn.Linear(d_model, d_k * n_heads)\n","    self.value = nn.Linear(d_model, d_k * n_heads)\n","\n","    # final linear layer\n","    self.fc = nn.Linear(d_k * n_heads, d_model)\n","\n","  def forward(self, q, k, v, mask=None):\n","    # h -> Number of attention heads\n","    q = self.query(q)   # [N, T, d_model] --> [N, T, h*d_k]\n","    k = self.key(k)     # [N, T, d_model] --> [N, T, h*d_k]\n","    v = self.value(v)   # [N, T, d_model] --> [N, T, h*d_v]\n","\n","    N = q.shape[0]    # batch size\n","    T = q.shape[1]    # sequence length\n","\n","    # make the following change in shape:\n","    # [N, T, h, d_k (or d_v)] --> [N, h, T, d_k (or d_v)]\n","    # in order for multiplication to work properly\n","    q = q.view(N, T, self.n_heads, self.d_k).transpose(1, 2)\n","    k = k.view(N, T, self.n_heads, self.d_k).transpose(1, 2)\n","    v = v.view(N, T, self.n_heads, self.d_k).transpose(1, 2)\n","\n","    # compute attention weights\n","    # [N, h, T, d_k] x [N, h, d_k, T] --> [N, h, T, T]\n","    attention_scores = q @ k.transpose(-2, -1) / math.sqrt(self.d_k)\n","    if mask is not None:\n","      attention_scores = attention_scores.masked_fill(\n","          mask[:, None, None, :] == 0, float('-inf')\n","      )\n","    attention_weights = F.softmax(attention_scores, dim=-1)\n","\n","    # compute attention-weighted values\n","    # [N, h, T, T] x [N, h, T, d_k] --> [N, h, T, d_k]\n","    A = attention_weights @ v\n","\n","    # reshape it back before final linear layer\n","    A = A.transpose(1, 2)   # [N, T, h, d_k]\n","    A = A.contiguous().view(N, T, self.d_k * self.n_heads)    # [N, T, h*d_k]\n","\n","    # projection\n","    return self.fc(A)"],"metadata":{"id":"KPQ_Wu5z_VWU","executionInfo":{"status":"ok","timestamp":1684946176937,"user_tz":-180,"elapsed":4,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["class TransformerBlock(nn.Module):\n","  def __init__(self, d_k, d_model, n_heads, dropout_prob=0.1):\n","    super().__init__()\n","\n","    self.ln1 = nn.LayerNorm(d_model)\n","    self.ln2 = nn.LayerNorm(d_model)\n","    self.mha = MultiHeadAttention(d_k, d_model, n_heads)\n","    self.ann = nn.Sequential(\n","        nn.Linear(d_model, 4 * d_model),\n","        nn.GELU(),\n","        nn.Linear(4 * d_model, d_model),\n","        nn.GELU(),\n","        nn.Dropout(p=dropout_prob),\n","    )\n","    self.dropout = nn.Dropout(p=dropout_prob)\n","\n","  def forward(self, x, mask=None):\n","    x = self.ln1(x + self.mha(x, x, x, mask))\n","    x = self.ln2(x + self.ann(x))\n","    x = self.dropout(x)\n","    return x"],"metadata":{"id":"mWpFelw8HIi5","executionInfo":{"status":"ok","timestamp":1684946176938,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","  def __init__(self, d_model, max_len=1024, dropout_prob=0.1):\n","    super().__init__()\n","    self.dropout = nn.Dropout(p=dropout_prob)\n","\n","    position = torch.arange(max_len).unsqueeze(1)\n","    exp_term = torch.arange(0, d_model, 2)\n","    div_term = torch.exp(exp_term * (-math.log(10000.0) / d_model))\n","    pe = torch.zeros(1, max_len, d_model)\n","    pe[0, :, 0::2] = torch.sin(position * div_term)\n","    pe[0, :, 1::2] = torch.cos(position * div_term)\n","    self.register_buffer('pe', pe)\n","\n","  def forward(self, x):\n","    # x --> [N, T, D]\n","    x = x + self.pe[:, :x.size(1), :]\n","    return self.dropout(x)"],"metadata":{"id":"ZSE02BEKJMYN","executionInfo":{"status":"ok","timestamp":1684946176938,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["class Encoder(nn.Module):\n","  def __init__(self,\n","               D,\n","               max_len,\n","               d_k,\n","               d_model,\n","               n_heads,\n","               n_layers,\n","               output_units,\n","               dropout_prob):\n","    super().__init__()\n","\n","    # self.conv1d = nn.Conv1d(in_channels=D,\n","    #                         out_channels=d_model,\n","    #                         kernel_size=1)\n","    self.linear = nn.Linear(D, d_model)\n","    self.relu = nn.ReLU()\n","    self.pos_encoding = PositionalEncoding(d_model,\n","                                           max_len,\n","                                           dropout_prob)\n","    transformer_blocks = [\n","        TransformerBlock(\n","            d_k,\n","            d_model,\n","            n_heads,\n","            dropout_prob) for _ in range(n_layers)]\n","    self.transformer_blocks = nn.Sequential(*transformer_blocks)\n","    self.ln = nn.LayerNorm(d_model)\n","    self.fc = nn.Linear(d_model, output_units)\n","\n","  def forward(self, x, mask=None):\n","    # x = self.conv1d(x).transpose(1, 2)\n","    x = self.relu(self.linear(x))\n","    x = self.pos_encoding(x)\n","    for block in self.transformer_blocks:\n","      x = block(x, mask)\n","    \n","    # many-to-one (x --> [N, T, D])\n","    x = x[:, 0, :]\n","\n","    x = self.ln(x)\n","    x = self.fc(x)\n","    return x"],"metadata":{"id":"3LoBGSruLv7_","executionInfo":{"status":"ok","timestamp":1684946176939,"user_tz":-180,"elapsed":6,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":["## Training and Evaluation"],"metadata":{"id":"xF7JUjfxbfyE"}},{"cell_type":"code","source":["def loss_fn(y_preds, y_true, device):\n","  epsilon = 1.17e-06\n","  loss = torch.zeros(1, requires_grad=True).to(device)\n","  abs_diff = torch.abs(y_preds - y_true)\n","  abs_per_error = abs_diff / torch.clamp(torch.abs(y_true), min=epsilon)\n","  mape = torch.sum(abs_per_error) / y_true.numel()\n","\n","  return mape   #+ 0.5 * torch.max(torch.tensor([[0., mape-2]])) * mape\n","\n","def train_step(model,\n","               dataloader, \n","               optimizer, \n","               device):\n","  \n","  model.train()\n","  loss = 0\n","  for batch, (X, y) in enumerate(dataloader):\n","    X, y = X.to(device), y.to(device)\n","    y_preds = model(X).squeeze().to(device)\n","    batch_loss = loss_fn(y_preds, y, device) \n","    loss += batch_loss.item()\n","    optimizer.zero_grad()\n","    batch_loss.backward()\n","    optimizer.step()\n","  \n","  loss /= len(dataloader)\n","  return loss\n","\n","def val_step(model, dataloader, device):\n","  model.eval()\n","  val_loss = 0\n","  with torch.inference_mode():\n","    for batch, (X, y) in enumerate(dataloader):\n","      X, y = X.to(device), y.to(device)\n","      val_preds = model(X).squeeze().to(device)\n","\n","      y_unscaled = scaler.data_min_[TARGET_POS] + y * (scaler.data_max_[TARGET_POS] - scaler.data_min_[TARGET_POS])\n","      y_preds_unscaled = scaler.data_min_[TARGET_POS] + val_preds * (scaler.data_max_[TARGET_POS] - scaler.data_min_[TARGET_POS])\n","\n","      batch_loss = loss_fn(y_preds_unscaled, y_unscaled, device)\n","      val_loss += batch_loss.item()\n","  \n","  val_loss /= len(dataloader)\n","  return val_loss\n","\n","def train(model, \n","          train_dataloader,\n","          val_dataloader,\n","          optimizer,\n","          scheduler,\n","          epochs,\n","          patience,\n","          device,\n","          path):\n","  \n","  results = {\n","      \"loss\": [],\n","      \"val_loss\": []\n","  }\n","\n","  for epoch in tqdm(range(epochs)):\n","    flag = 0\n","    loss = train_step(model=model,\n","                      dataloader=train_dataloader,\n","                      optimizer=optimizer,\n","                      device=device)\n","\n","    val_loss = val_step(model=model,\n","                        dataloader=val_dataloader,\n","                        device=device)\n","    scheduler.step(val_loss)\n","    \n","    results['loss'].append(loss)\n","    results['val_loss'].append(val_loss)\n","    if epoch == 0:\n","      best_val_loss = val_loss\n","      best_epoch = -1\n","      checkpoint(model, optimizer, path)\n","      flag = 1\n","      print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f} - *Checkpoint*\")\n","    else:\n","      if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_epoch = epoch\n","        checkpoint(model, optimizer, path)\n","        flag = 1\n","        print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f} - *Checkpoint*\")\n","      elif epoch - best_epoch > patience:\n","        print(f\"\\nEarly stopping applied at epoch {epoch}.\")\n","        break\n","    if flag == 0:\n","      print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f}\")\n","  \n","  return results\n","\n","def checkpoint(model, optimizer, filepath):\n","  torch.save({\n","    \"optimizer\": optimizer.state_dict(),\n","    \"model\": model.state_dict()\n","  }, filepath)"],"metadata":{"id":"s2egVAsMZW6Z","executionInfo":{"status":"ok","timestamp":1684946176939,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":27,"outputs":[]},{"cell_type":"markdown","source":["# MAIN 1"],"metadata":{"id":"eIVX98nwON0c"}},{"cell_type":"code","source":["N = 8\n","T = 168\n","D = 11\n","\n","model = Encoder(max_len=1024, \n","                D=11,\n","                d_k=16, \n","                d_model=64, \n","                n_heads=4, \n","                n_layers=2, \n","                output_units=24, \n","                dropout_prob=0.1)\n","\n","x = np.random.randn(N, T, D)\n","x_t = torch.tensor(x, dtype=torch.float32)\n","print(f\"Initial tensor: Shape --> {x_t.size()}\")\n","\n","x_t_tr = x_t.transpose(1, 2)\n","print(f\"Tensor transposed: Shape --> {x_t_tr.size()}\")\n","\n","conv1d = nn.Conv1d(in_channels=D,\n","                   out_channels=64,\n","                   kernel_size=1)\n","\n","x_t_tr = conv1d(x_t_tr)\n","print(f\"Tensor after Conv1d: Shape --> {x_t_tr.size()}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ngXAcRjYONVC","executionInfo":{"status":"ok","timestamp":1681137591923,"user_tz":-180,"elapsed":437,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"308dc7ce-8e8f-4475-f8e1-2d4c00226545"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial tensor: Shape --> torch.Size([8, 168, 11])\n","Tensor transposed: Shape --> torch.Size([8, 11, 168])\n","Tensor after Conv1d: Shape --> torch.Size([8, 64, 168])\n"]}]},{"cell_type":"code","source":["N = 8\n","T = 168\n","D = 11\n","d_model = 64\n","\n","model = Encoder(max_len=1024, \n","                D=11,\n","                d_k=16, \n","                d_model=64, \n","                n_heads=4, \n","                n_layers=2, \n","                output_units=24, \n","                dropout_prob=0.1)\n","\n","x = np.random.randn(N, T, D)\n","x_t = torch.tensor(x, dtype=torch.float32)\n","print(f\"Initial tensor: Shape --> {x_t.size()}\")\n","\n","linear = nn.Linear(D, d_model)\n","x_l = linear(x_t)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mY9y9N4N7bIu","executionInfo":{"status":"ok","timestamp":1681137592513,"user_tz":-180,"elapsed":4,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"01874d4a-e68d-4e55-dfcd-38d31a25fa98"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Initial tensor: Shape --> torch.Size([8, 168, 11])\n"]}]},{"cell_type":"code","source":["x_l.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GRZujwkVODyO","executionInfo":{"status":"ok","timestamp":1681137592513,"user_tz":-180,"elapsed":3,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"780616ea-2f70-499f-bec9-871e30b35885"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([8, 168, 64])"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","source":["# MAIN 2"],"metadata":{"id":"waEWWevba5jX"}},{"cell_type":"code","source":["DAYS_BACK = 3\n","DAYS_TO_SKIP = 10\n","STEPS_FORWARD = 24    # 1 day\n","SKIP_STEPS_FORWARD = 24 * DAYS_TO_SKIP\n","LAST_STEP_FORWARD = STEPS_FORWARD + SKIP_STEPS_FORWARD\n","LAST_STEP_BACK = 24 * DAYS_BACK\n","\n","# keep 1 year for testing\n","START_TEST_DATE = pd.to_datetime('2018-01-01') - pd.to_timedelta(LAST_STEP_FORWARD, 'h')\n","END_TEST_DATE = START_TEST_DATE + pd.DateOffset(years=1)\n","\n","END_VAL_DATE = START_TEST_DATE - pd.to_timedelta(1, 'h')\n","START_VAL_DATE = pd.to_datetime('2017-01-01') - pd.to_timedelta(LAST_STEP_FORWARD, 'h')\n","\n","START_TRAIN_DATE = pd.to_datetime('2010-10-01')\n","END_TRAIN_DATE = START_VAL_DATE - pd.to_timedelta(1, 'h')\n","\n","TARGET = \"TOTAL_CONS\"\n","\n","BATCH_SIZE = 1024\n","EPOCHS = 1000\n","PATIENCE = 22\n","PATH = \"model.pth\"\n","\n","print(f\"Train from {START_TRAIN_DATE} to {END_TRAIN_DATE}\")\n","print(f\"Validation from {START_VAL_DATE} to {END_VAL_DATE}\")\n","print(f\"Test from {START_TEST_DATE} to {END_TEST_DATE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cy3AXiz2yQjN","executionInfo":{"status":"ok","timestamp":1684946183232,"user_tz":-180,"elapsed":4,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"a4754601-3420-42bf-9221-b6c71df22f5f"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Train from 2010-10-01 00:00:00 to 2016-12-20 23:00:00\n","Validation from 2016-12-21 00:00:00 to 2017-12-20 23:00:00\n","Test from 2017-12-21 00:00:00 to 2018-12-21 00:00:00\n"]}]},{"cell_type":"code","source":["load_df = pd.read_csv(\"/content/FINAL_DATASET_2.csv\")\n","load_df.set_index(pd.to_datetime(load_df[\"Timestamp\"]), inplace=True)\n","load_df.drop(\"Timestamp\", axis=1, inplace=True)\n","\n","TARGET_POS = np.where(load_df.columns == TARGET)[0][0]\n","\n","load_df_scaled, scaler = scale_data(load_df,\n","                                    START_TRAIN_DATE,\n","                                    END_VAL_DATE,\n","                                    START_TEST_DATE,\n","                                    END_TEST_DATE)\n","\n","load_df_scaled_reframed = reframe_data(load_df_scaled, \n","                                       TARGET,\n","                                       DAYS_BACK,\n","                                       LAST_STEP_FORWARD,\n","                                       LAST_STEP_BACK,\n","                                       SKIP_STEPS_FORWARD)\n","\n"],"metadata":{"id":"6cRrYOkQmUgs","executionInfo":{"status":"ok","timestamp":1684946184201,"user_tz":-180,"elapsed":972,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["X_train_3D, X_val_3D, X_test_3D, y_train_df, y_val_df, y_test_df = split_data(load_df_scaled_reframed,\n","                                                                              START_TRAIN_DATE,\n","                                                                              END_TRAIN_DATE,\n","                                                                              START_VAL_DATE,\n","                                                                              END_VAL_DATE,\n","                                                                              START_TEST_DATE,\n","                                                                              END_TEST_DATE,\n","                                                                              STEPS_FORWARD,\n","                                                                              LAST_STEP_BACK)\n","\n","# X_train_3D = np.transpose(X_train_3D, (0, 2, 1))\n","# X_val_3D = np.transpose(X_val_3D, (0, 2, 1))\n","# X_test_3D = np.transpose(X_test_3D, (0, 2, 1))\n","\n","train_dataset = LoadDataset(X_3D=X_train_3D, \n","                            y_df=y_train_df)\n","train_dataloader = DataLoader(dataset=train_dataset, \n","                              batch_size=BATCH_SIZE,\n","                              shuffle=True)\n","\n","val_dataset = LoadDataset(X_3D=X_val_3D,\n","                          y_df=y_val_df)\n","val_dataloader = DataLoader(dataset=val_dataset,\n","                            batch_size=BATCH_SIZE)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HiHc8rNPkuEo","executionInfo":{"status":"ok","timestamp":1684946185088,"user_tz":-180,"elapsed":891,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"962cf23b-9c2d-4466-dad0-3cb7446e0fcf"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["(54481, 72, 8)\n","(8760, 72, 8)\n","(8497, 72, 8)\n"]}]},{"cell_type":"code","source":["model = Encoder(D=X_train_3D.shape[2],\n","                max_len=LAST_STEP_BACK, \n","                d_k=16, \n","                d_model=64, \n","                n_heads=16, \n","                n_layers=2, \n","                output_units=24, \n","                dropout_prob=0).to(device)\n","# loss_fn = CustomLoss(device=device)     # MeanAbsolutePercentageError().to(device)\n","optimizer = torch.optim.Adam(params=model.parameters())\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.33, patience=7, verbose=True)"],"metadata":{"id":"YOrl-5I6Qmnh","executionInfo":{"status":"ok","timestamp":1684946185088,"user_tz":-180,"elapsed":4,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["!rm -rf \"model.pth\"\n","start_time = datetime.now()\n","\n","model_results = train(model=model, \n","                      train_dataloader=train_dataloader,\n","                      val_dataloader=val_dataloader,\n","                      optimizer=optimizer,\n","                      scheduler=scheduler,\n","                      epochs=EPOCHS,\n","                      patience=PATIENCE,\n","                      device=device,\n","                      path=PATH)\n","\n","total_time = datetime.now() - start_time\n","print(f\"Total training time: {total_time.seconds}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0,"referenced_widgets":["3e7fd7632c274b46b559edb4930d5860","a113dc9999e34cb3b969fbce9aeb5075","e8ad0d0e9b1c4659bc98a57bb667394c","20c6ab3f21cd4a21a54246fbf24bf9cd","e5a1a2d2b51c4c089f7f8706c044420c","6c1e8097156442a69e74c6bd90e22709","11bcb41b799a408baf5dd7ec2cf4c464","2bf43df710134212adfc8cbe11002ff7","642107b41a0a4b1d8cfb7628a9f0c720","e486d7e424b643bc8e304fa0b3366a40","4efe0870baf0410aa0f0885398c84973"]},"id":"sI8MZ-vndz7_","executionInfo":{"status":"ok","timestamp":1684946607831,"user_tz":-180,"elapsed":422746,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"ed01e660-d674-4fb3-e5aa-9af131ba404c"},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e7fd7632c274b46b559edb4930d5860"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1/1000 | Loss: 0.4562 | Val loss: 0.1446 - *Checkpoint*\n","Epoch: 2/1000 | Loss: 0.3021 | Val loss: 0.1147 - *Checkpoint*\n","Epoch: 3/1000 | Loss: 0.2197 | Val loss: 0.0847 - *Checkpoint*\n","Epoch: 4/1000 | Loss: 0.1762 | Val loss: 0.0771 - *Checkpoint*\n","Epoch: 5/1000 | Loss: 0.1609 | Val loss: 0.0733 - *Checkpoint*\n","Epoch: 6/1000 | Loss: 0.1540 | Val loss: 0.0772\n","Epoch: 7/1000 | Loss: 0.1489 | Val loss: 0.0783\n","Epoch: 8/1000 | Loss: 0.1465 | Val loss: 0.0840\n","Epoch: 9/1000 | Loss: 0.1461 | Val loss: 0.0817\n","Epoch: 10/1000 | Loss: 0.1413 | Val loss: 0.0841\n","Epoch: 11/1000 | Loss: 0.1371 | Val loss: 0.0925\n","Epoch: 12/1000 | Loss: 0.1365 | Val loss: 0.0661 - *Checkpoint*\n","Epoch: 13/1000 | Loss: 0.1331 | Val loss: 0.0944\n","Epoch: 14/1000 | Loss: 0.1341 | Val loss: 0.0658 - *Checkpoint*\n","Epoch: 15/1000 | Loss: 0.1284 | Val loss: 0.0706\n","Epoch: 16/1000 | Loss: 0.1298 | Val loss: 0.0644 - *Checkpoint*\n","Epoch: 17/1000 | Loss: 0.1268 | Val loss: 0.0632 - *Checkpoint*\n","Epoch: 18/1000 | Loss: 0.1248 | Val loss: 0.0877\n","Epoch: 19/1000 | Loss: 0.1287 | Val loss: 0.0640\n","Epoch: 20/1000 | Loss: 0.1208 | Val loss: 0.0694\n","Epoch: 21/1000 | Loss: 0.1211 | Val loss: 0.0706\n","Epoch: 22/1000 | Loss: 0.1176 | Val loss: 0.0962\n","Epoch: 23/1000 | Loss: 0.1180 | Val loss: 0.0671\n","Epoch: 24/1000 | Loss: 0.1154 | Val loss: 0.0800\n","Epoch: 25/1000 | Loss: 0.1161 | Val loss: 0.0591 - *Checkpoint*\n","Epoch: 26/1000 | Loss: 0.1132 | Val loss: 0.0578 - *Checkpoint*\n","Epoch: 27/1000 | Loss: 0.1124 | Val loss: 0.0751\n","Epoch: 28/1000 | Loss: 0.1125 | Val loss: 0.0701\n","Epoch: 29/1000 | Loss: 0.1101 | Val loss: 0.0776\n","Epoch: 30/1000 | Loss: 0.1095 | Val loss: 0.0686\n","Epoch: 31/1000 | Loss: 0.1078 | Val loss: 0.0673\n","Epoch: 32/1000 | Loss: 0.1166 | Val loss: 0.0665\n","Epoch: 33/1000 | Loss: 0.1044 | Val loss: 0.0843\n","Epoch 00034: reducing learning rate of group 0 to 3.3000e-04.\n","Epoch: 34/1000 | Loss: 0.1052 | Val loss: 0.0610\n","Epoch: 35/1000 | Loss: 0.1006 | Val loss: 0.0705\n","Epoch: 36/1000 | Loss: 0.0996 | Val loss: 0.0711\n","Epoch: 37/1000 | Loss: 0.0997 | Val loss: 0.0691\n","Epoch: 38/1000 | Loss: 0.0992 | Val loss: 0.0723\n","Epoch: 39/1000 | Loss: 0.0989 | Val loss: 0.0732\n","Epoch: 40/1000 | Loss: 0.0991 | Val loss: 0.0656\n","Epoch: 41/1000 | Loss: 0.0988 | Val loss: 0.0666\n","Epoch 00042: reducing learning rate of group 0 to 1.0890e-04.\n","Epoch: 42/1000 | Loss: 0.0989 | Val loss: 0.0655\n","Epoch: 43/1000 | Loss: 0.0976 | Val loss: 0.0690\n","Epoch: 44/1000 | Loss: 0.0976 | Val loss: 0.0691\n","Epoch: 45/1000 | Loss: 0.0973 | Val loss: 0.0757\n","Epoch: 46/1000 | Loss: 0.0973 | Val loss: 0.0730\n","Epoch: 47/1000 | Loss: 0.0972 | Val loss: 0.0731\n","Epoch: 48/1000 | Loss: 0.0973 | Val loss: 0.0679\n","\n","Early stopping applied at epoch 48.\n","Total training time: 422\n"]}]},{"cell_type":"code","source":["checkpoint = torch.load(\"model.pth\")\n","model.load_state_dict(checkpoint['model'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","model.to(\"cpu\")\n","model.eval()\n","with torch.inference_mode():\n","  test_preds_scaled = model(torch.tensor(X_test_3D, dtype=torch.float32))\n","test_preds_scaled = test_preds_scaled.to('cpu').squeeze().numpy()\n","\n","test_preds_df_scaled = pd.DataFrame(test_preds_scaled, columns=np.arange(1, STEPS_FORWARD+1), index=y_test_df.index)\n","test_preds_df = pd.DataFrame(columns=np.arange(1, STEPS_FORWARD+1), index=test_preds_df_scaled.index)\n","for i, col in enumerate(test_preds_df_scaled.columns):\n","  test_preds_df[i+1] = scaler.data_min_[TARGET_POS] + test_preds_df_scaled[col].to_numpy() * (scaler.data_max_[TARGET_POS] - scaler.data_min_[TARGET_POS])\n","\n","real_df = pd.DataFrame(columns=np.arange(1, STEPS_FORWARD+1), index=test_preds_df.index)\n","for i, col in enumerate(y_test_df.columns):\n","  real_df[i+1] = scaler.data_min_[TARGET_POS] + y_test_df[col].to_numpy() * (scaler.data_max_[TARGET_POS] - scaler.data_min_[TARGET_POS])"],"metadata":{"id":"PFvF3h-7cXg3","executionInfo":{"status":"ok","timestamp":1684946615676,"user_tz":-180,"elapsed":7856,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["mape_list = list()\n","step_results_dict = {}\n","for step in range(1, STEPS_FORWARD + 1):\n","  step_index = real_df.index + pd.to_timedelta(SKIP_STEPS_FORWARD + step, 'h')\n","  step_results_df = pd.DataFrame(\n","      {\n","          \"real\": real_df.loc[:, step].to_numpy(),\n","          \"predictions\": test_preds_df.loc[:, step].to_numpy()\n","      },\n","      index=step_index\n","  )\n","  step_results_df['abs_error'] = abs(step_results_df['real'] - step_results_df['predictions'])\n","  step_results_df['ape'] = np.where(step_results_df['real'] == 0, np.NaN, 100 * step_results_df['abs_error']/step_results_df['real'])\n","  step_mape = step_results_df['ape'].mean()\n","  mape_list.append(step_mape)\n","  print(f\"Step {step} -> MAPE = {step_mape}\")\n","\n","  step_results_dict[step] = step_results_df\n","mape = np.array(mape_list).mean()\n","print(f\"\\nMAPE = {mape}\")"],"metadata":{"id":"EJSskMCYKBb5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684946616275,"user_tz":-180,"elapsed":603,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"76bf34e9-8bf0-4f0c-e687-8c0dc8ffc9c5"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 1 -> MAPE = 6.766741693219503\n","Step 2 -> MAPE = 6.513291396075378\n","Step 3 -> MAPE = 6.820129854769707\n","Step 4 -> MAPE = 7.387675011771584\n","Step 5 -> MAPE = 6.833579693935906\n","Step 6 -> MAPE = 6.82063152209729\n","Step 7 -> MAPE = 7.236267655494694\n","Step 8 -> MAPE = 6.552955851597608\n","Step 9 -> MAPE = 7.376416312203048\n","Step 10 -> MAPE = 8.119207270024487\n","Step 11 -> MAPE = 7.961007202671249\n","Step 12 -> MAPE = 7.270224421597464\n","Step 13 -> MAPE = 7.119189813083537\n","Step 14 -> MAPE = 7.332779853735236\n","Step 15 -> MAPE = 7.56923777872741\n","Step 16 -> MAPE = 7.115979621419861\n","Step 17 -> MAPE = 7.064788854556921\n","Step 18 -> MAPE = 6.447440553542124\n","Step 19 -> MAPE = 5.904684651089301\n","Step 20 -> MAPE = 6.404453900214577\n","Step 21 -> MAPE = 6.899925463324453\n","Step 22 -> MAPE = 6.57716059747167\n","Step 23 -> MAPE = 7.354279246190304\n","Step 24 -> MAPE = 7.629932135621643\n","\n","MAPE = 7.044915848101456\n"]}]}]}