{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","toc_visible":true,"authorship_tag":"ABX9TyOij1+alkKAUDJ04n4I4wIm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"e7526d7cf3104979b368dabd1b307e80":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d6baaa304e6c4a099fcc815d4ce2f134","IPY_MODEL_7b8737695d944dd291fede0571e49d7e","IPY_MODEL_6a8cf989b3a24ec794cdf9d942f5bac6"],"layout":"IPY_MODEL_2b5eaa535f014a2f8c31b38e3e567a9f"}},"d6baaa304e6c4a099fcc815d4ce2f134":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c0f78c1067f4a3a9530713ac3b2a33c","placeholder":"​","style":"IPY_MODEL_2036ee4bcec24de290fa87671715562c","value":"  5%"}},"7b8737695d944dd291fede0571e49d7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fa233c1d79a41c2ba4536e7c3df6e0a","max":2000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0dc9299ec0934eb6a48445ae490b3d94","value":102}},"6a8cf989b3a24ec794cdf9d942f5bac6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e204ffd234f472bb58f20b88bf994a4","placeholder":"​","style":"IPY_MODEL_65ce1dbc25784c6b8b0f224926e4afc6","value":" 102/2000 [00:52&lt;16:36,  1.90it/s]"}},"2b5eaa535f014a2f8c31b38e3e567a9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8c0f78c1067f4a3a9530713ac3b2a33c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2036ee4bcec24de290fa87671715562c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8fa233c1d79a41c2ba4536e7c3df6e0a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0dc9299ec0934eb6a48445ae490b3d94":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4e204ffd234f472bb58f20b88bf994a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65ce1dbc25784c6b8b0f224926e4afc6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f0bef78e41e14fdb9c95e88908ccf186":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8a1b2a01cc084f539da1872e096b0513","IPY_MODEL_c2f259fa98de4f33b039817664c75583","IPY_MODEL_a9136d814eba4760a77616aa4443ab8c"],"layout":"IPY_MODEL_a1cfbc6a895440ea8c5c3c92d83a80cc"}},"8a1b2a01cc084f539da1872e096b0513":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9228c9bf0560444a9a9efd983c5df5bf","placeholder":"​","style":"IPY_MODEL_1dd18f59eeed42b6a9669ae32779cd53","value":"  8%"}},"c2f259fa98de4f33b039817664c75583":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9a1a9b0b1774ac28003c281a5d25039","max":1000,"min":0,"orientation":"horizontal","style":"IPY_MODEL_18de3904c3b8423f8bb5ee84ee16fe3c","value":78}},"a9136d814eba4760a77616aa4443ab8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e8177dcc35ee4a759fa0f678792e09f9","placeholder":"​","style":"IPY_MODEL_c82ab06bdda147bdacf3b8601969e298","value":" 78/1000 [01:16&lt;14:46,  1.04it/s]"}},"a1cfbc6a895440ea8c5c3c92d83a80cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9228c9bf0560444a9a9efd983c5df5bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1dd18f59eeed42b6a9669ae32779cd53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a9a1a9b0b1774ac28003c281a5d25039":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18de3904c3b8423f8bb5ee84ee16fe3c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e8177dcc35ee4a759fa0f678792e09f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c82ab06bdda147bdacf3b8601969e298":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Installs + Imports"],"metadata":{"id":"-ab2qm_WcYTh"}},{"cell_type":"code","source":["import math\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler, MaxAbsScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from tqdm.auto import tqdm\n","from datetime import datetime \n","from torch.optim.lr_scheduler import ReduceLROnPlateau"],"metadata":{"id":"hrEAsoZx_B8n","executionInfo":{"status":"ok","timestamp":1684598316689,"user_tz":-180,"elapsed":790,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["# Helpers"],"metadata":{"id":"yCQf7lLIPXJA"}},{"cell_type":"code","source":["class LoadDataset(Dataset):\n","  def __init__(self, X_df, y_df):\n","    self.X = torch.tensor(X_df.values, dtype=torch.float32)\n","    self.y = torch.tensor(y_df.values, dtype=torch.float32)\n","  \n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self, idx):\n","    return self.X[idx], self.y[idx]"],"metadata":{"id":"hgiBrHrSU3eY","executionInfo":{"status":"ok","timestamp":1684599704651,"user_tz":-180,"elapsed":4,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["class FeedForward(nn.Module):\n","  def __init__(self,\n","               n_layers,\n","               layers,\n","               activation=nn.ReLU()):\n","\n","    super().__init__()\n","    self.n_layers = n_layers \n","    self.layers = layers\n","    self.activation = activation\n","\n","    dense_layers = [\n","        self.dense_layer(in_features=self.layers[i],\n","                         out_features=self.layers[i+1])\n","        for i in range(self.n_layers-1)]\n","    dense_layers.append(nn.Linear(in_features=self.layers[-2],\n","                                  out_features=self.layers[-1]))\n","\n","    self.feed_forward = nn.Sequential(*dense_layers)\n","\n","  def dense_layer(self, in_features, out_features):\n","    dense_layer = nn.Sequential(\n","      nn.Linear(in_features=in_features,\n","                out_features=out_features),\n","      self.activation,\n","    )\n","    return dense_layer\n","  \n","  def forward(self, x):\n","    return self.feed_forward(x)"],"metadata":{"id":"R-OL46d7PYli","executionInfo":{"status":"ok","timestamp":1684599704651,"user_tz":-180,"elapsed":3,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["def mape(y_preds, y_true):\n","  epsilon = 1.17e-06\n","  abs_diff = torch.abs(y_preds - y_true)\n","  abs_per_error = abs_diff / torch.clamp(torch.abs(y_true), min=epsilon)\n","  mape = torch.sum(abs_per_error) / y_true.numel()\n","\n","  return mape \n","\n","# def loss_fn(y_preds, y):\n","#   loss = mape(y_preds, y) * (1 + 0.4 * torch.max(torch.tensor([0, mape(y_preds, y) - 2])))\n","#   return loss.requires_grad_(True)\n","\n","def loss_fn(y_preds, y):\n","  MAPE = mape(y_preds, y)\n","  loss = MAPE if MAPE < 10 else torch.exp(MAPE - 10) \n","  return loss.requires_grad_(True)\n","\n","def train_step(model,\n","               dataloader, \n","               optimizer, \n","               device):\n","  \n","  model.train()\n","  loss = 0\n","  for batch, (X, y) in enumerate(dataloader):\n","    X, y = X.to(device), y.to(device)\n","    y_preds = model(X).squeeze()\n","    batch_loss = loss_fn(y_preds, y)\n","    loss += batch_loss.item()\n","    optimizer.zero_grad()\n","    batch_loss.backward()\n","    optimizer.step()\n","  \n","  loss /= len(dataloader)\n","  return loss\n","\n","def val_step(model, dataloader, device):\n","  model.eval()\n","  val_loss = 0\n","  with torch.inference_mode():\n","    for batch, (X, y) in enumerate(dataloader):\n","      X, y = X.to(device), y.to(device)\n","      y_preds = model(X).squeeze()\n","\n","      y_preds_unscaled = y_preds * scaler.max_abs_[TARGET_POS]\n","      y_true_unscaled  = y * scaler.max_abs_[TARGET_POS] \n","\n","      batch_loss = 100 * mape(y_preds_unscaled, y_true_unscaled) \n","      val_loss += batch_loss.item()\n","  \n","  val_loss /= len(dataloader)\n","  return val_loss\n","\n","def train(model, \n","          train_dataloader,\n","          val_dataloader,\n","          optimizer,\n","          scheduler,\n","          epochs,\n","          patience,\n","          device,\n","          path):\n","  \n","  results = {\n","      \"loss\": [],\n","      \"val_loss\": []\n","  }\n","\n","  for epoch in tqdm(range(epochs)):\n","    flag = 0\n","    loss = train_step(model=model,\n","                      dataloader=train_dataloader,\n","                      optimizer=optimizer,\n","                      device=device)\n","\n","    val_loss = val_step(model=model,\n","                        dataloader=val_dataloader,\n","                        device=device)\n","    scheduler.step(val_loss)\n","    \n","    results['loss'].append(loss)\n","    results['val_loss'].append(val_loss)\n","    if epoch == 0:\n","      best_val_loss = val_loss\n","      best_epoch = -1\n","      checkpoint(model, optimizer, path)\n","      flag = 1\n","      print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f} - *Checkpoint*\")\n","    else:\n","      if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_epoch = epoch\n","        checkpoint(model, optimizer, path)\n","        flag = 1\n","        print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f} - *Checkpoint*\")\n","      elif epoch - best_epoch > patience:\n","        print(f\"\\nEarly stopping applied at epoch {epoch}.\")\n","        break\n","    if flag == 0:\n","      print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f}\")\n","  \n","  return results\n","\n","def checkpoint(model, optimizer, filepath):\n","  torch.save({\n","    \"optimizer\": optimizer.state_dict(),\n","    \"model\": model.state_dict()\n","  }, filepath)"],"metadata":{"id":"s2egVAsMZW6Z","executionInfo":{"status":"ok","timestamp":1684599704651,"user_tz":-180,"elapsed":3,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["# Preprocessing"],"metadata":{"id":"k2Figsi7B9tl"}},{"cell_type":"code","source":["TARGET = \"TOTAL_CONS\"\n","\n","# keep 1 year for testing\n","START_TEST_DATE = pd.to_datetime('2018-01-01')\n","END_TEST_DATE = START_TEST_DATE + pd.DateOffset(years=1)\n","\n","END_VAL_DATE = START_TEST_DATE - pd.to_timedelta(1, 'h')\n","START_VAL_DATE = pd.to_datetime('2017-01-01')\n","\n","START_TRAIN_DATE = pd.to_datetime('2010-01-01')\n","END_TRAIN_DATE = START_VAL_DATE - pd.to_timedelta(1, 'h')\n","\n","DAYS_BACK_TO_SKIP = 0\n","\n","START_STEP_FORWARD = 24 * 10\n","LAST_STEP_FORWARD = START_STEP_FORWARD + 24\n","STEPS_BACKWARD_START = 24 * DAYS_BACK_TO_SKIP\n","\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'"],"metadata":{"id":"4es0BU7DGCdn","executionInfo":{"status":"ok","timestamp":1684599691405,"user_tz":-180,"elapsed":2,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/FINAL_DATASET_2.csv\")\n","df.set_index(pd.to_datetime(df[\"Timestamp\"]), inplace=True)\n","df.drop(\"Timestamp\", axis=1, inplace=True)\n","df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"5bZqaUwnB6za","executionInfo":{"status":"ok","timestamp":1684599692823,"user_tz":-180,"elapsed":445,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"3e040aa8-b98e-4f35-eb71-12fc94e2e188"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     TOTAL_CONS  Weekend  Holiday   temp  humidity  hour  \\\n","Timestamp                                                                  \n","2010-10-01 00:00:00    4390.054        0        0  16.12      79.0     0   \n","2010-10-01 01:00:00    4046.071        0        0  15.19      77.0     1   \n","2010-10-01 02:00:00    3885.451        0        0  14.65      82.0     2   \n","2010-10-01 03:00:00    3808.100        0        0  14.03      71.0     3   \n","2010-10-01 04:00:00    3782.623        0        0  13.29      77.0     4   \n","...                         ...      ...      ...    ...       ...   ...   \n","2020-11-22 19:00:00    4281.942        1        0  10.74      54.0    19   \n","2020-11-22 20:00:00    4091.488        1        0  10.15      51.0    20   \n","2020-11-22 21:00:00    3738.827        1        0   9.81      51.0    21   \n","2020-11-22 22:00:00    3461.113        1        0   9.67      54.0    22   \n","2020-11-22 23:00:00    3107.457        1        0   9.18      54.0    23   \n","\n","                     weekday  dayofyear  \n","Timestamp                                \n","2010-10-01 00:00:00        4        274  \n","2010-10-01 01:00:00        4        274  \n","2010-10-01 02:00:00        4        274  \n","2010-10-01 03:00:00        4        274  \n","2010-10-01 04:00:00        4        274  \n","...                      ...        ...  \n","2020-11-22 19:00:00        6        327  \n","2020-11-22 20:00:00        6        327  \n","2020-11-22 21:00:00        6        327  \n","2020-11-22 22:00:00        6        327  \n","2020-11-22 23:00:00        6        327  \n","\n","[88944 rows x 8 columns]"],"text/html":["\n","  <div id=\"df-a04949fc-4e70-47f5-ac85-e9740a686a15\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TOTAL_CONS</th>\n","      <th>Weekend</th>\n","      <th>Holiday</th>\n","      <th>temp</th>\n","      <th>humidity</th>\n","      <th>hour</th>\n","      <th>weekday</th>\n","      <th>dayofyear</th>\n","    </tr>\n","    <tr>\n","      <th>Timestamp</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2010-10-01 00:00:00</th>\n","      <td>4390.054</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>16.12</td>\n","      <td>79.0</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>274</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 01:00:00</th>\n","      <td>4046.071</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>15.19</td>\n","      <td>77.0</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>274</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 02:00:00</th>\n","      <td>3885.451</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14.65</td>\n","      <td>82.0</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>274</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 03:00:00</th>\n","      <td>3808.100</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>14.03</td>\n","      <td>71.0</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>274</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 04:00:00</th>\n","      <td>3782.623</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>13.29</td>\n","      <td>77.0</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>274</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 19:00:00</th>\n","      <td>4281.942</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>10.74</td>\n","      <td>54.0</td>\n","      <td>19</td>\n","      <td>6</td>\n","      <td>327</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 20:00:00</th>\n","      <td>4091.488</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>10.15</td>\n","      <td>51.0</td>\n","      <td>20</td>\n","      <td>6</td>\n","      <td>327</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 21:00:00</th>\n","      <td>3738.827</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9.81</td>\n","      <td>51.0</td>\n","      <td>21</td>\n","      <td>6</td>\n","      <td>327</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 22:00:00</th>\n","      <td>3461.113</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9.67</td>\n","      <td>54.0</td>\n","      <td>22</td>\n","      <td>6</td>\n","      <td>327</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 23:00:00</th>\n","      <td>3107.457</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>9.18</td>\n","      <td>54.0</td>\n","      <td>23</td>\n","      <td>6</td>\n","      <td>327</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>88944 rows × 8 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a04949fc-4e70-47f5-ac85-e9740a686a15')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a04949fc-4e70-47f5-ac85-e9740a686a15 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a04949fc-4e70-47f5-ac85-e9740a686a15');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["TARGET_POS = np.where(df.columns == TARGET)[0][0]\n","\n","train_val_df = df[(df.index >= START_TRAIN_DATE) & (df.index <= END_VAL_DATE)]\n","test_df = df[(df.index >= START_TEST_DATE)]\n","\n","scaler = MaxAbsScaler()    # MinMaxScaler()\n","train_val_scaled = scaler.fit_transform(train_val_df)\n","train_val_df_scaled = pd.DataFrame(train_val_scaled,\n","                                   columns=train_val_df.columns,\n","                                   index=train_val_df.index)\n","test_scaled = scaler.transform(test_df)\n","test_df_scaled = pd.DataFrame(test_scaled,\n","                              columns=test_df.columns,\n","                              index=test_df.index)\n","\n","scaled_df = pd.concat([train_val_df_scaled, test_df_scaled], axis=0)\n","scaled_df.drop(['humidity', 'hour', 'dayofyear'], axis=1, inplace=True)\n","scaled_df"],"metadata":{"id":"ldMwQIQYIlFS","executionInfo":{"status":"ok","timestamp":1684599692824,"user_tz":-180,"elapsed":8,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"colab":{"base_uri":"https://localhost:8080/","height":0},"outputId":"bd0256f1-404f-442b-bcc5-4ba1f7d42cb1"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     TOTAL_CONS  Weekend  Holiday      temp   weekday\n","Timestamp                                                            \n","2010-10-01 00:00:00    0.443017      0.0      0.0  0.419682  0.666667\n","2010-10-01 01:00:00    0.408305      0.0      0.0  0.395470  0.666667\n","2010-10-01 02:00:00    0.392096      0.0      0.0  0.381411  0.666667\n","2010-10-01 03:00:00    0.384290      0.0      0.0  0.365269  0.666667\n","2010-10-01 04:00:00    0.381719      0.0      0.0  0.346004  0.666667\n","...                         ...      ...      ...       ...       ...\n","2020-11-22 19:00:00    0.432107      1.0      0.0  0.279615  1.000000\n","2020-11-22 20:00:00    0.412888      1.0      0.0  0.264254  1.000000\n","2020-11-22 21:00:00    0.377299      1.0      0.0  0.255402  1.000000\n","2020-11-22 22:00:00    0.349274      1.0      0.0  0.251757  1.000000\n","2020-11-22 23:00:00    0.313585      1.0      0.0  0.239000  1.000000\n","\n","[88944 rows x 5 columns]"],"text/html":["\n","  <div id=\"df-0068c372-9a0f-438b-818b-eca1e33eeacf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TOTAL_CONS</th>\n","      <th>Weekend</th>\n","      <th>Holiday</th>\n","      <th>temp</th>\n","      <th>weekday</th>\n","    </tr>\n","    <tr>\n","      <th>Timestamp</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2010-10-01 00:00:00</th>\n","      <td>0.443017</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.419682</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 01:00:00</th>\n","      <td>0.408305</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.395470</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 02:00:00</th>\n","      <td>0.392096</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.381411</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 03:00:00</th>\n","      <td>0.384290</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.365269</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-01 04:00:00</th>\n","      <td>0.381719</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.346004</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 19:00:00</th>\n","      <td>0.432107</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.279615</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 20:00:00</th>\n","      <td>0.412888</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.264254</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 21:00:00</th>\n","      <td>0.377299</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.255402</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 22:00:00</th>\n","      <td>0.349274</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.251757</td>\n","      <td>1.000000</td>\n","    </tr>\n","    <tr>\n","      <th>2020-11-22 23:00:00</th>\n","      <td>0.313585</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.239000</td>\n","      <td>1.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>88944 rows × 5 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0068c372-9a0f-438b-818b-eca1e33eeacf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0068c372-9a0f-438b-818b-eca1e33eeacf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0068c372-9a0f-438b-818b-eca1e33eeacf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["# Training + Inference (one step at a time)"],"metadata":{"id":"0kdu2OftNHqY"}},{"cell_type":"code","source":["mape_list = list()\n","# for step_forward in np.arange(START_STEP_FORWARD, LAST_STEP_FORWARD + 1, step=1):\n","for step_forward in range(1):\n","\n","  scaled_df_copy = scaled_df.copy()  # pd.DataFrame()\n","\n","  # *** shift Weather + Time data ***\n","  for col in scaled_df.drop(TARGET, axis=1).columns:\n","    scaled_df_copy[col + f\"_(t+{step_forward})\"] = scaled_df[col].shift(-step_forward)\n","    scaled_df_copy.drop(col, axis=1, inplace=True)\n","\n","  # ---------- REFRAMING -----------------\n","  # *** shift Target ***\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","\n","  # *** shift Backsteps *** \n","  for day_back in np.arange(DAYS_BACK_TO_SKIP + 1, DAYS_BACK_TO_SKIP + 10, step=1):\n","    step_back = 24 * day_back - step_forward\n","    scaled_df_copy[TARGET + f\"_(t-{step_back})\"] = scaled_df[TARGET].shift(step_back)\n","      \n","  refr_df = scaled_df_copy.drop(TARGET, axis=1).copy()\n","  refr_df.dropna(inplace=True)\n","\n","  # print()\n","  # print(np.abs(refr_df.corr())[TARGET + f\"_(t+{step_forward})\"])\n","  # print()\n","  # print(refr_df.columns)\n","\n","  # split to train, validation and test sets\n","  train_df_refr = refr_df[(refr_df.index >= START_TRAIN_DATE) & (refr_df.index <= END_TRAIN_DATE)]\n","  val_df_refr = refr_df[(refr_df.index >= START_VAL_DATE) & (refr_df.index <= END_VAL_DATE)]\n","  test_df_refr = refr_df[(refr_df.index >= START_TEST_DATE) & (refr_df.index <= END_TEST_DATE)]\n","\n","  # shuffle train set\n","  train_df_refr = shuffle(train_df_refr)\n","\n","  # split to features and targets\n","  X_train_df = train_df_refr.drop(TARGET + f\"_(t+{step_forward})\", axis=1)\n","  y_train_df = train_df_refr[TARGET + f\"_(t+{step_forward})\"]\n","\n","  X_val_df = val_df_refr.drop(TARGET + f\"_(t+{step_forward})\", axis=1)\n","  y_val_df = val_df_refr[TARGET + f\"_(t+{step_forward})\"]\n","\n","  X_test_df = test_df_refr.drop(TARGET + f\"_(t+{step_forward})\", axis=1)\n","  y_test_df = test_df_refr[TARGET + f\"_(t+{step_forward})\"]\n","\n","  # *** DATALOADERS ***\n","  train_dataset = LoadDataset(X_df=X_train_df,\n","                              y_df=y_train_df)\n","  train_dataloader = DataLoader(dataset=train_dataset, \n","                                batch_size=BATCH_SIZE,\n","                                shuffle=True)\n","\n","  val_dataset = LoadDataset(X_df=X_val_df,\n","                            y_df=y_val_df)\n","  val_dataloader = DataLoader(dataset=val_dataset, \n","                              batch_size=BATCH_SIZE,\n","                              shuffle=False)\n","  \n","  test_dataset = LoadDataset(X_df=X_test_df,\n","                             y_df=y_test_df)\n","  test_dataloader = DataLoader(dataset=test_dataset, \n","                               batch_size=BATCH_SIZE,\n","                               shuffle=False)\n","\n","  # Defince the model\n","  N_NEURONS = 32\n","  LAYERS = [X_train_df.shape[1], 300, 100, 1]\n","  N_LAYERS = len(LAYERS) - 1\n","  model = FeedForward(n_layers=N_LAYERS,\n","                    layers=LAYERS,\n","                    activation=nn.ReLU()).to(device)\n","  !rm -rf \"model.pth\"\n","  optimizer = torch.optim.Adam(params=model.parameters(),\n","                               lr=1e-3,\n","                               weight_decay=0)\n","  # optimizer = t.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n","  scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.33, patience=15, verbose=True)\n","\n","  # Training Feed-Forward ...\n","  model_results = train(model=model, \n","                        train_dataloader=train_dataloader,\n","                        val_dataloader=val_dataloader,\n","                        optimizer=optimizer,\n","                        scheduler=scheduler,\n","                        epochs=EPOCHS,\n","                        patience=PATIENCE,\n","                        device=device,\n","                        path=PATH)\n","  \n","  # Inference\n","  model.eval()\n","  with torch.inference_mode():\n","    for batch, (X_test, y_test) in enumerate(test_dataloader):\n","      X_test, y_test= X_test.to(device), y_test.to(device)\n","      test_batch_preds = model(X_test).squeeze()\n","      if batch == 0:\n","        y_step_preds_scaled = test_batch_preds\n","        y_step_test_scaled = y_test\n","      else:\n","        y_step_preds_scaled = torch.cat((y_step_preds_scaled, test_batch_preds), dim=0)\n","        y_step_test_scaled = torch.cat((y_step_test_scaled, y_test), dim=0)\n","\n","  y_step_preds = y_step_preds_scaled.to('cpu').numpy() * scaler.max_abs_[TARGET_POS]\n","  y_step_test = y_step_test_scaled.to('cpu').numpy() * scaler.max_abs_[TARGET_POS] \n","\n","  step_results = pd.DataFrame(\n","      {\n","        \"real\": y_step_test,\n","        \"predictions\": y_step_preds\n","      },\n","      index=y_test_df.index + pd.to_timedelta(step_forward, 'h')\n","  )\n","\n","  step_results['abs_error'] = np.abs(step_results[\"real\"] - step_results[\"predictions\"])\n","  step_results['ape'] = np.where(step_results[\"real\"] == 0, np.NaN, 100 * step_results['abs_error'] / step_results[\"real\"])\n","  step_mape = step_results['ape'].mean()\n","  mape_list.append(step_mape)\n","\n","  print(f\"step {step_forward} -> MAPE = {step_mape}%\")\n","MAPE = np.mean(np.array(mape_list))\n","print(f\"\\nOverall MAPE = {MAPE}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e7526d7cf3104979b368dabd1b307e80","d6baaa304e6c4a099fcc815d4ce2f134","7b8737695d944dd291fede0571e49d7e","6a8cf989b3a24ec794cdf9d942f5bac6","2b5eaa535f014a2f8c31b38e3e567a9f","8c0f78c1067f4a3a9530713ac3b2a33c","2036ee4bcec24de290fa87671715562c","8fa233c1d79a41c2ba4536e7c3df6e0a","0dc9299ec0934eb6a48445ae490b3d94","4e204ffd234f472bb58f20b88bf994a4","65ce1dbc25784c6b8b0f224926e4afc6"]},"id":"3dBcC1HkSxuz","executionInfo":{"status":"ok","timestamp":1681757017923,"user_tz":-180,"elapsed":52664,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"947f6a36-c8ed-4f28-a335-790b590bd4af"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7526d7cf3104979b368dabd1b307e80"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1/2000 | Loss: 0.4034 | Val loss: 14.8940 - *Checkpoint*\n","Epoch: 2/2000 | Loss: 0.1136 | Val loss: 11.8796 - *Checkpoint*\n","Epoch: 3/2000 | Loss: 0.0845 | Val loss: 8.8849 - *Checkpoint*\n","Epoch: 4/2000 | Loss: 0.0737 | Val loss: 8.0902 - *Checkpoint*\n","Epoch: 5/2000 | Loss: 0.0698 | Val loss: 7.6466 - *Checkpoint*\n","Epoch: 6/2000 | Loss: 0.0681 | Val loss: 7.5322 - *Checkpoint*\n","Epoch: 7/2000 | Loss: 0.0672 | Val loss: 7.6659\n","Epoch: 8/2000 | Loss: 0.0668 | Val loss: 7.4491 - *Checkpoint*\n","Epoch: 9/2000 | Loss: 0.0657 | Val loss: 7.2932 - *Checkpoint*\n","Epoch: 10/2000 | Loss: 0.0648 | Val loss: 7.2889 - *Checkpoint*\n","Epoch: 11/2000 | Loss: 0.0643 | Val loss: 7.3525\n","Epoch: 12/2000 | Loss: 0.0634 | Val loss: 7.1298 - *Checkpoint*\n","Epoch: 13/2000 | Loss: 0.0628 | Val loss: 7.0305 - *Checkpoint*\n","Epoch: 14/2000 | Loss: 0.0621 | Val loss: 7.1869\n","Epoch: 15/2000 | Loss: 0.0617 | Val loss: 6.9078 - *Checkpoint*\n","Epoch: 16/2000 | Loss: 0.0610 | Val loss: 7.0095\n","Epoch: 17/2000 | Loss: 0.0605 | Val loss: 6.6830 - *Checkpoint*\n","Epoch: 18/2000 | Loss: 0.0602 | Val loss: 6.8976\n","Epoch: 19/2000 | Loss: 0.0598 | Val loss: 6.7393\n","Epoch: 20/2000 | Loss: 0.0592 | Val loss: 6.7912\n","Epoch: 21/2000 | Loss: 0.0590 | Val loss: 7.2445\n","Epoch: 22/2000 | Loss: 0.0586 | Val loss: 7.0961\n","Epoch: 23/2000 | Loss: 0.0586 | Val loss: 6.8531\n","Epoch: 24/2000 | Loss: 0.0580 | Val loss: 6.5795 - *Checkpoint*\n","Epoch: 25/2000 | Loss: 0.0584 | Val loss: 6.5764 - *Checkpoint*\n","Epoch: 26/2000 | Loss: 0.0579 | Val loss: 7.5416\n","Epoch: 27/2000 | Loss: 0.0581 | Val loss: 7.4668\n","Epoch: 28/2000 | Loss: 0.0576 | Val loss: 6.8033\n","Epoch: 29/2000 | Loss: 0.0571 | Val loss: 6.8095\n","Epoch: 30/2000 | Loss: 0.0569 | Val loss: 6.6275\n","Epoch: 31/2000 | Loss: 0.0569 | Val loss: 6.5541 - *Checkpoint*\n","Epoch: 32/2000 | Loss: 0.0565 | Val loss: 7.0445\n","Epoch: 33/2000 | Loss: 0.0566 | Val loss: 6.3984 - *Checkpoint*\n","Epoch: 34/2000 | Loss: 0.0566 | Val loss: 6.5604\n","Epoch: 35/2000 | Loss: 0.0560 | Val loss: 6.4397\n","Epoch: 36/2000 | Loss: 0.0563 | Val loss: 7.0443\n","Epoch: 37/2000 | Loss: 0.0558 | Val loss: 6.9847\n","Epoch: 38/2000 | Loss: 0.0557 | Val loss: 6.3543 - *Checkpoint*\n","Epoch: 39/2000 | Loss: 0.0558 | Val loss: 6.8177\n","Epoch: 40/2000 | Loss: 0.0554 | Val loss: 6.5119\n","Epoch: 41/2000 | Loss: 0.0555 | Val loss: 7.4487\n","Epoch: 42/2000 | Loss: 0.0554 | Val loss: 6.7626\n","Epoch: 43/2000 | Loss: 0.0549 | Val loss: 6.6939\n","Epoch: 44/2000 | Loss: 0.0548 | Val loss: 6.4664\n","Epoch: 45/2000 | Loss: 0.0550 | Val loss: 7.5985\n","Epoch: 46/2000 | Loss: 0.0547 | Val loss: 6.6869\n","Epoch: 47/2000 | Loss: 0.0544 | Val loss: 7.2544\n","Epoch: 48/2000 | Loss: 0.0541 | Val loss: 6.7760\n","Epoch: 49/2000 | Loss: 0.0538 | Val loss: 6.7405\n","Epoch: 50/2000 | Loss: 0.0535 | Val loss: 6.8346\n","Epoch: 51/2000 | Loss: 0.0538 | Val loss: 6.5968\n","Epoch: 52/2000 | Loss: 0.0533 | Val loss: 6.2740 - *Checkpoint*\n","Epoch: 53/2000 | Loss: 0.0532 | Val loss: 6.3914\n","Epoch: 54/2000 | Loss: 0.0531 | Val loss: 7.1648\n","Epoch: 55/2000 | Loss: 0.0533 | Val loss: 6.8430\n","Epoch: 56/2000 | Loss: 0.0528 | Val loss: 6.4785\n","Epoch: 57/2000 | Loss: 0.0527 | Val loss: 6.5789\n","Epoch: 58/2000 | Loss: 0.0528 | Val loss: 6.9352\n","Epoch: 59/2000 | Loss: 0.0526 | Val loss: 6.7522\n","Epoch: 60/2000 | Loss: 0.0523 | Val loss: 6.6759\n","Epoch: 61/2000 | Loss: 0.0524 | Val loss: 6.1637 - *Checkpoint*\n","Epoch: 62/2000 | Loss: 0.0521 | Val loss: 6.0558 - *Checkpoint*\n","Epoch: 63/2000 | Loss: 0.0523 | Val loss: 6.2350\n","Epoch: 64/2000 | Loss: 0.0524 | Val loss: 7.4539\n","Epoch: 65/2000 | Loss: 0.0526 | Val loss: 6.3059\n","Epoch: 66/2000 | Loss: 0.0517 | Val loss: 6.1190\n","Epoch: 67/2000 | Loss: 0.0515 | Val loss: 6.8203\n","Epoch: 68/2000 | Loss: 0.0512 | Val loss: 7.1341\n","Epoch: 69/2000 | Loss: 0.0514 | Val loss: 6.6791\n","Epoch: 70/2000 | Loss: 0.0508 | Val loss: 6.4836\n","Epoch: 71/2000 | Loss: 0.0507 | Val loss: 5.9519 - *Checkpoint*\n","Epoch: 72/2000 | Loss: 0.0519 | Val loss: 7.4231\n","Epoch: 73/2000 | Loss: 0.0510 | Val loss: 6.3580\n","Epoch: 74/2000 | Loss: 0.0506 | Val loss: 6.8604\n","Epoch: 75/2000 | Loss: 0.0505 | Val loss: 6.5821\n","Epoch: 76/2000 | Loss: 0.0503 | Val loss: 6.4746\n","Epoch: 77/2000 | Loss: 0.0502 | Val loss: 6.7368\n","Epoch: 78/2000 | Loss: 0.0501 | Val loss: 6.8030\n","Epoch: 79/2000 | Loss: 0.0502 | Val loss: 6.2708\n","Epoch: 80/2000 | Loss: 0.0501 | Val loss: 6.4959\n","Epoch: 81/2000 | Loss: 0.0499 | Val loss: 6.2026\n","Epoch: 82/2000 | Loss: 0.0499 | Val loss: 7.2821\n","Epoch: 83/2000 | Loss: 0.0498 | Val loss: 6.2906\n","Epoch: 84/2000 | Loss: 0.0496 | Val loss: 6.8588\n","Epoch: 85/2000 | Loss: 0.0494 | Val loss: 7.3023\n","Epoch: 86/2000 | Loss: 0.0494 | Val loss: 6.0687\n","Epoch 00087: reducing learning rate of group 0 to 3.3000e-04.\n","Epoch: 87/2000 | Loss: 0.0495 | Val loss: 7.5029\n","Epoch: 88/2000 | Loss: 0.0492 | Val loss: 6.7223\n","Epoch: 89/2000 | Loss: 0.0490 | Val loss: 6.3970\n","Epoch: 90/2000 | Loss: 0.0492 | Val loss: 6.5696\n","Epoch: 91/2000 | Loss: 0.0488 | Val loss: 6.6355\n","Epoch: 92/2000 | Loss: 0.0488 | Val loss: 6.7727\n","Epoch: 93/2000 | Loss: 0.0487 | Val loss: 6.7412\n","Epoch: 94/2000 | Loss: 0.0487 | Val loss: 6.5802\n","Epoch: 95/2000 | Loss: 0.0487 | Val loss: 6.5643\n","Epoch: 96/2000 | Loss: 0.0488 | Val loss: 6.8935\n","Epoch: 97/2000 | Loss: 0.0487 | Val loss: 6.7056\n","Epoch: 98/2000 | Loss: 0.0486 | Val loss: 7.0280\n","Epoch: 99/2000 | Loss: 0.0486 | Val loss: 6.8508\n","Epoch: 100/2000 | Loss: 0.0486 | Val loss: 6.9756\n","Epoch: 101/2000 | Loss: 0.0487 | Val loss: 6.4200\n","Epoch: 102/2000 | Loss: 0.0485 | Val loss: 6.9440\n","Epoch 00103: reducing learning rate of group 0 to 1.0890e-04.\n","\n","Early stopping applied at epoch 102.\n","step 0 -> MAPE = 7.891197681427002%\n","\n","Overall MAPE = 7.891197681427002%\n"]}]},{"cell_type":"code","source":["df[df.index == '2018-01-01 00:00:00']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":112},"id":"pCXGYqgSbDPR","executionInfo":{"status":"ok","timestamp":1681756289067,"user_tz":-180,"elapsed":24,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"e6bd13cb-4fcd-4402-98c8-fb8148f0ec3e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            TOTAL_CONS  Weekend  Holiday  temp  humidity  hour  weekday  \\\n","Timestamp                                                                 \n","2018-01-01    4681.077        0        1  3.12      93.0     0        0   \n","\n","            dayofyear  \n","Timestamp              \n","2018-01-01          1  "],"text/html":["\n","  <div id=\"df-e30e6a46-1461-467c-a5e0-6805fd858c03\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TOTAL_CONS</th>\n","      <th>Weekend</th>\n","      <th>Holiday</th>\n","      <th>temp</th>\n","      <th>humidity</th>\n","      <th>hour</th>\n","      <th>weekday</th>\n","      <th>dayofyear</th>\n","    </tr>\n","    <tr>\n","      <th>Timestamp</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2018-01-01</th>\n","      <td>4681.077</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>3.12</td>\n","      <td>93.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e30e6a46-1461-467c-a5e0-6805fd858c03')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e30e6a46-1461-467c-a5e0-6805fd858c03 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e30e6a46-1461-467c-a5e0-6805fd858c03');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":91}]},{"cell_type":"code","source":["model.state_dict"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gp9-vCuia_E9","executionInfo":{"status":"ok","timestamp":1681756320972,"user_tz":-180,"elapsed":929,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"3e949107-f417-4afd-a8c6-a2b980f2b571"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<bound method Module.state_dict of FeedForward(\n","  (activation): ReLU()\n","  (feed_forward): Sequential(\n","    (0): Sequential(\n","      (0): Linear(in_features=17, out_features=256, bias=True)\n","      (1): ReLU()\n","    )\n","    (1): Sequential(\n","      (0): Linear(in_features=256, out_features=256, bias=True)\n","      (1): ReLU()\n","    )\n","    (2): Sequential(\n","      (0): Linear(in_features=256, out_features=256, bias=True)\n","      (1): ReLU()\n","    )\n","    (3): Linear(in_features=256, out_features=1, bias=True)\n","  )\n",")>"]},"metadata":{},"execution_count":93}]},{"cell_type":"markdown","source":["# Training + Inference (all steps together)"],"metadata":{"id":"SQ9AYY9yGWuo"}},{"cell_type":"code","source":["! rm -rf \"model.pth\"\n","EPOCHS = 1000\n","PATIENCE = 31\n","PATH = \"model.pth\"\n","BATCH_SIZE = 1024\n","\n","mape_list = list()\n","scaled_df_copy = scaled_df.copy()\n","\n","# *** shift future Time data ***\n","for col in ['Weekend', 'Holiday', 'weekday']:\n","  scaled_df_copy[col + f\"_(t+{START_STEP_FORWARD})\"] = scaled_df[col].shift(-START_STEP_FORWARD)\n","  scaled_df_copy.drop(col, axis=1, inplace=True)\n","\n","# *** shift future Weather data ***\n","for col in ['temp']:\n","  for i in range(START_STEP_FORWARD + 1, LAST_STEP_FORWARD + 1):\n","    scaled_df_copy[col + f\"_(t+{i})\"] = scaled_df[col].shift(-i)\n","\n","# ---------- REFRAMING -----------------\n","# *** shift Backsteps *** \n","for col in ['temp', TARGET]:\n","  for day_back in [0, 1, 6]:\n","    for i in range(24):\n","      step_back = day_back * 24 + i\n","      scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","\n","# *** shift Target ***\n","for step_forward in range(START_STEP_FORWARD + 1, LAST_STEP_FORWARD + 1):\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","    \n","refr_df = scaled_df_copy.drop(['temp', TARGET], axis=1)\n","refr_df.dropna(inplace=True)\n","\n","# print()\n","# print(np.abs(refr_df.corr())[TARGET + f\"_(t+{1})\"])\n","# print()\n","# print(refr_df.columns)\n","\n","# split to train, validation and test sets\n","train_df_refr = refr_df[(refr_df.index >= START_TRAIN_DATE) & (refr_df.index <= END_TRAIN_DATE)]\n","val_df_refr = refr_df[(refr_df.index >= START_VAL_DATE) & (refr_df.index <= END_VAL_DATE)]\n","test_df_refr = refr_df[(refr_df.index >= START_TEST_DATE) & (refr_df.index <= END_TEST_DATE)]\n","\n","# shuffle train set\n","train_df_refr = shuffle(train_df_refr)\n","\n","# split to features and targets\n","X_train_df = train_df_refr.iloc[:, :-24]\n","y_train_df = train_df_refr.iloc[:, -24:]\n","\n","X_val_df = val_df_refr.iloc[:, :-24]\n","y_val_df = val_df_refr.iloc[:, -24:]\n","\n","X_test_df = test_df_refr.iloc[:, :-24]\n","y_test_df = test_df_refr.iloc[:, -24:]\n","\n","# *** DATALOADERS ***\n","train_dataset = LoadDataset(X_df=X_train_df,\n","                            y_df=y_train_df)\n","train_dataloader = DataLoader(dataset=train_dataset, \n","                              batch_size=BATCH_SIZE,\n","                              shuffle=True)\n","\n","val_dataset = LoadDataset(X_df=X_val_df,\n","                          y_df=y_val_df)\n","val_dataloader = DataLoader(dataset=val_dataset, \n","                            batch_size=BATCH_SIZE,\n","                            shuffle=False)\n","\n","test_dataset = LoadDataset(X_df=X_test_df,\n","                            y_df=y_test_df)\n","test_dataloader = DataLoader(dataset=test_dataset, \n","                              batch_size=BATCH_SIZE,\n","                              shuffle=False)\n","\n","# Defince the model\n","LAYERS = [X_train_df.shape[1], 300, 100, 24]\n","N_LAYERS = len(LAYERS) - 1\n","model = FeedForward(n_layers=N_LAYERS,\n","                  layers=LAYERS,\n","                  activation=nn.ReLU()).to(device)\n","!rm -rf \"model.pth\"\n","optimizer = torch.optim.Adam(params=model.parameters(),\n","                              lr=1e-3,\n","                              weight_decay=0)\n","# optimizer = t.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.33, patience=15, verbose=True)\n","\n","# Training Feed-Forward ...\n","model_results = train(model=model, \n","                      train_dataloader=train_dataloader,\n","                      val_dataloader=val_dataloader,\n","                      optimizer=optimizer,\n","                      scheduler=scheduler,\n","                      epochs=EPOCHS,\n","                      patience=PATIENCE,\n","                      device=device,\n","                      path=PATH)\n","\n","# Inference\n","model.eval()\n","with torch.inference_mode():\n","  for batch, (X_test, y_test) in enumerate(test_dataloader):\n","    X_test, y_test= X_test.to(device), y_test.to(device)\n","    test_batch_preds = model(X_test).squeeze()\n","    if batch == 0:\n","      y_preds_scaled = test_batch_preds\n","      y_test_scaled = y_test\n","    else:\n","      y_preds_scaled = torch.cat((y_preds_scaled, test_batch_preds), dim=0)\n","      y_test_scaled = torch.cat((y_test_scaled, y_test), dim=0)\n","\n","y_preds = y_preds_scaled.to('cpu').numpy() * scaler.max_abs_[TARGET_POS]\n","y_test = y_test_scaled.to('cpu').numpy() * scaler.max_abs_[TARGET_POS] \n","\n","mape_list = list()\n","step_results_dict = {}\n","for step in range(1, 24 + 1):\n","  step_index = y_test_df.index + pd.to_timedelta(step, 'h')\n","  step_results_df = pd.DataFrame(\n","      {\n","          \"real\": y_test[:, step-1],\n","          \"predictions\": y_preds[:, step-1]\n","      },\n","      index=step_index\n","  )\n","  step_results_df['abs_error'] = abs(step_results_df['real'] - step_results_df['predictions'])\n","  step_results_df['ape'] = np.where(step_results_df['real'] == 0, np.NaN, 100 * step_results_df['abs_error']/step_results_df['real'])\n","  step_mape = step_results_df['ape'].mean()\n","  mape_list.append(step_mape)\n","  print(f\"Step {step} -> MAPE = {step_mape}\")\n","\n","  step_results_dict[step] = step_results_df\n","mape = np.array(mape_list).mean()\n","print(f\"\\nMAPE = {mape}\")"],"metadata":{"id":"cbvl0RJNb57N","executionInfo":{"status":"ok","timestamp":1684599787514,"user_tz":-180,"elapsed":80593,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["f0bef78e41e14fdb9c95e88908ccf186","8a1b2a01cc084f539da1872e096b0513","c2f259fa98de4f33b039817664c75583","a9136d814eba4760a77616aa4443ab8c","a1cfbc6a895440ea8c5c3c92d83a80cc","9228c9bf0560444a9a9efd983c5df5bf","1dd18f59eeed42b6a9669ae32779cd53","a9a1a9b0b1774ac28003c281a5d25039","18de3904c3b8423f8bb5ee84ee16fe3c","e8177dcc35ee4a759fa0f678792e09f9","c82ab06bdda147bdacf3b8601969e298"]},"outputId":"7fa39858-98e8-4f20-e74e-f87ce1b12352"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[col + f\"_(t-{step_back})\"] = scaled_df[col].shift(step_back)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n","<ipython-input-24-98d87e73e4b6>:30: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n","  scaled_df_copy[TARGET + f\"_(t+{step_forward})\"] = scaled_df[TARGET].shift(-step_forward)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/1000 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0bef78e41e14fdb9c95e88908ccf186"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1/1000 | Loss: 0.2596 | Val loss: 12.7100 - *Checkpoint*\n","Epoch: 2/1000 | Loss: 0.1080 | Val loss: 10.0835 - *Checkpoint*\n","Epoch: 3/1000 | Loss: 0.0897 | Val loss: 9.3620 - *Checkpoint*\n","Epoch: 4/1000 | Loss: 0.0818 | Val loss: 8.5446 - *Checkpoint*\n","Epoch: 5/1000 | Loss: 0.0753 | Val loss: 8.0250 - *Checkpoint*\n","Epoch: 6/1000 | Loss: 0.0692 | Val loss: 7.8186 - *Checkpoint*\n","Epoch: 7/1000 | Loss: 0.0663 | Val loss: 7.2096 - *Checkpoint*\n","Epoch: 8/1000 | Loss: 0.0657 | Val loss: 8.5980\n","Epoch: 9/1000 | Loss: 0.0638 | Val loss: 7.0983 - *Checkpoint*\n","Epoch: 10/1000 | Loss: 0.0631 | Val loss: 8.0411\n","Epoch: 11/1000 | Loss: 0.0623 | Val loss: 7.1282\n","Epoch: 12/1000 | Loss: 0.0610 | Val loss: 6.8545 - *Checkpoint*\n","Epoch: 13/1000 | Loss: 0.0607 | Val loss: 6.9921\n","Epoch: 14/1000 | Loss: 0.0597 | Val loss: 6.7794 - *Checkpoint*\n","Epoch: 15/1000 | Loss: 0.0590 | Val loss: 7.3291\n","Epoch: 16/1000 | Loss: 0.0589 | Val loss: 6.9272\n","Epoch: 17/1000 | Loss: 0.0585 | Val loss: 6.7417 - *Checkpoint*\n","Epoch: 18/1000 | Loss: 0.0579 | Val loss: 7.8630\n","Epoch: 19/1000 | Loss: 0.0575 | Val loss: 6.2780 - *Checkpoint*\n","Epoch: 20/1000 | Loss: 0.0574 | Val loss: 6.8594\n","Epoch: 21/1000 | Loss: 0.0565 | Val loss: 7.0153\n","Epoch: 22/1000 | Loss: 0.0575 | Val loss: 7.4223\n","Epoch: 23/1000 | Loss: 0.0570 | Val loss: 6.6012\n","Epoch: 24/1000 | Loss: 0.0561 | Val loss: 6.0564 - *Checkpoint*\n","Epoch: 25/1000 | Loss: 0.0562 | Val loss: 6.9584\n","Epoch: 26/1000 | Loss: 0.0557 | Val loss: 6.6784\n","Epoch: 27/1000 | Loss: 0.0555 | Val loss: 7.0663\n","Epoch: 28/1000 | Loss: 0.0565 | Val loss: 7.8472\n","Epoch: 29/1000 | Loss: 0.0551 | Val loss: 7.5013\n","Epoch: 30/1000 | Loss: 0.0553 | Val loss: 6.5139\n","Epoch: 31/1000 | Loss: 0.0542 | Val loss: 7.0699\n","Epoch: 32/1000 | Loss: 0.0550 | Val loss: 5.8614 - *Checkpoint*\n","Epoch: 33/1000 | Loss: 0.0543 | Val loss: 6.5696\n","Epoch: 34/1000 | Loss: 0.0544 | Val loss: 6.3166\n","Epoch: 35/1000 | Loss: 0.0537 | Val loss: 6.7617\n","Epoch: 36/1000 | Loss: 0.0536 | Val loss: 6.6728\n","Epoch: 37/1000 | Loss: 0.0539 | Val loss: 6.4633\n","Epoch: 38/1000 | Loss: 0.0538 | Val loss: 6.5127\n","Epoch: 39/1000 | Loss: 0.0534 | Val loss: 5.9119\n","Epoch: 40/1000 | Loss: 0.0534 | Val loss: 7.6617\n","Epoch: 41/1000 | Loss: 0.0529 | Val loss: 7.0246\n","Epoch: 42/1000 | Loss: 0.0529 | Val loss: 6.0988\n","Epoch: 43/1000 | Loss: 0.0532 | Val loss: 6.3615\n","Epoch: 44/1000 | Loss: 0.0524 | Val loss: 6.8693\n","Epoch: 45/1000 | Loss: 0.0528 | Val loss: 6.6874\n","Epoch: 46/1000 | Loss: 0.0519 | Val loss: 7.2290\n","Epoch: 47/1000 | Loss: 0.0518 | Val loss: 5.7037 - *Checkpoint*\n","Epoch: 48/1000 | Loss: 0.0519 | Val loss: 6.3150\n","Epoch: 49/1000 | Loss: 0.0515 | Val loss: 7.7407\n","Epoch: 50/1000 | Loss: 0.0515 | Val loss: 7.0234\n","Epoch: 51/1000 | Loss: 0.0522 | Val loss: 7.0696\n","Epoch: 52/1000 | Loss: 0.0510 | Val loss: 6.6260\n","Epoch: 53/1000 | Loss: 0.0513 | Val loss: 5.8352\n","Epoch: 54/1000 | Loss: 0.0513 | Val loss: 7.0557\n","Epoch: 55/1000 | Loss: 0.0512 | Val loss: 6.4799\n","Epoch: 56/1000 | Loss: 0.0503 | Val loss: 6.0289\n","Epoch: 57/1000 | Loss: 0.0509 | Val loss: 5.9705\n","Epoch: 58/1000 | Loss: 0.0509 | Val loss: 7.2090\n","Epoch: 59/1000 | Loss: 0.0502 | Val loss: 5.9120\n","Epoch: 60/1000 | Loss: 0.0503 | Val loss: 6.1255\n","Epoch: 61/1000 | Loss: 0.0509 | Val loss: 7.5176\n","Epoch: 62/1000 | Loss: 0.0502 | Val loss: 6.1300\n","Epoch 00063: reducing learning rate of group 0 to 3.3000e-04.\n","Epoch: 63/1000 | Loss: 0.0501 | Val loss: 6.2108\n","Epoch: 64/1000 | Loss: 0.0489 | Val loss: 6.3543\n","Epoch: 65/1000 | Loss: 0.0487 | Val loss: 6.2796\n","Epoch: 66/1000 | Loss: 0.0486 | Val loss: 6.5997\n","Epoch: 67/1000 | Loss: 0.0486 | Val loss: 6.3804\n","Epoch: 68/1000 | Loss: 0.0487 | Val loss: 6.6104\n","Epoch: 69/1000 | Loss: 0.0486 | Val loss: 6.2079\n","Epoch: 70/1000 | Loss: 0.0485 | Val loss: 6.1908\n","Epoch: 71/1000 | Loss: 0.0484 | Val loss: 6.3483\n","Epoch: 72/1000 | Loss: 0.0485 | Val loss: 6.1924\n","Epoch: 73/1000 | Loss: 0.0484 | Val loss: 6.2071\n","Epoch: 74/1000 | Loss: 0.0486 | Val loss: 6.4642\n","Epoch: 75/1000 | Loss: 0.0484 | Val loss: 6.1827\n","Epoch: 76/1000 | Loss: 0.0483 | Val loss: 6.1692\n","Epoch: 77/1000 | Loss: 0.0482 | Val loss: 5.9926\n","Epoch: 78/1000 | Loss: 0.0482 | Val loss: 6.2573\n","Epoch 00079: reducing learning rate of group 0 to 1.0890e-04.\n","\n","Early stopping applied at epoch 78.\n","Step 1 -> MAPE = 7.758632183074951\n","Step 2 -> MAPE = 7.686880111694336\n","Step 3 -> MAPE = 7.880661487579346\n","Step 4 -> MAPE = 8.047455787658691\n","Step 5 -> MAPE = 7.776991844177246\n","Step 6 -> MAPE = 8.234525680541992\n","Step 7 -> MAPE = 8.320792198181152\n","Step 8 -> MAPE = 8.492392539978027\n","Step 9 -> MAPE = 8.156537055969238\n","Step 10 -> MAPE = 7.778056621551514\n","Step 11 -> MAPE = 7.790757656097412\n","Step 12 -> MAPE = 8.310620307922363\n","Step 13 -> MAPE = 8.352469444274902\n","Step 14 -> MAPE = 8.207070350646973\n","Step 15 -> MAPE = 8.145787239074707\n","Step 16 -> MAPE = 8.360461235046387\n","Step 17 -> MAPE = 8.34479808807373\n","Step 18 -> MAPE = 8.415803909301758\n","Step 19 -> MAPE = 8.162518501281738\n","Step 20 -> MAPE = 8.167398452758789\n","Step 21 -> MAPE = 7.544241905212402\n","Step 22 -> MAPE = 7.260544776916504\n","Step 23 -> MAPE = 7.418833255767822\n","Step 24 -> MAPE = 7.440000534057617\n","\n","MAPE = 8.002259254455566\n"]}]},{"cell_type":"code","source":["step = 24\n","step_df = step_results_dict[step]\n","step_df['ape_above_10_flag'] = np.where(step_df['ape'] >= 10., 1, 0)\n","step_df_grouped = step_df.groupby(by=step_results_dict[1].index.month).sum()\n","step_df_grouped['ape_above_10_(%)'] = 100 * step_df_grouped['ape_above_10_flag'] / (30 * 24)\n","step_df_grouped"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":457},"id":"Ry6K_XyvOeg_","executionInfo":{"status":"ok","timestamp":1681805014326,"user_tz":-180,"elapsed":498,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"cd03a951-f42e-400d-e20c-d6e6eefcf9a5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                 real  predictions      abs_error          ape  \\\n","Timestamp                                                        \n","1          3961348.25   3944251.25  131140.531250  2459.629150   \n","2          3447525.50   3442842.00  108727.867188  2069.166260   \n","3          3401897.75   3438634.25  113911.335938  2467.267578   \n","4          2947588.25   3004475.00  119564.531250  2989.899170   \n","5          3119189.50   3156895.50   88695.554688  2125.302002   \n","6          3348490.75   3368263.00   88905.820312  1928.043091   \n","7          3920082.25   3928837.00  133205.937500  2531.140381   \n","8          3705299.25   3763367.50  121135.914062  2489.636230   \n","9          3223079.00   3263685.50   96946.265625  2161.520264   \n","10         2981794.50   2994979.75   92559.171875  2286.910156   \n","11         3202975.00   3188765.00  105034.132812  2305.686035   \n","12         3745193.25   3809881.75  144030.437500  2901.099121   \n","\n","           ape_above_10_flag  ape_above_10_(%)  \n","Timestamp                                       \n","1                         26          3.611111  \n","2                         24          3.333333  \n","3                         21          2.916667  \n","4                         55          7.638889  \n","5                          1          0.138889  \n","6                          2          0.277778  \n","7                         26          3.611111  \n","8                         20          2.777778  \n","9                         17          2.361111  \n","10                        14          1.944444  \n","11                        26          3.611111  \n","12                        55          7.638889  "],"text/html":["\n","  <div id=\"df-64e9a451-8990-4b6c-b8c3-77c24c91ce9f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>real</th>\n","      <th>predictions</th>\n","      <th>abs_error</th>\n","      <th>ape</th>\n","      <th>ape_above_10_flag</th>\n","      <th>ape_above_10_(%)</th>\n","    </tr>\n","    <tr>\n","      <th>Timestamp</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>3961348.25</td>\n","      <td>3944251.25</td>\n","      <td>131140.531250</td>\n","      <td>2459.629150</td>\n","      <td>26</td>\n","      <td>3.611111</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3447525.50</td>\n","      <td>3442842.00</td>\n","      <td>108727.867188</td>\n","      <td>2069.166260</td>\n","      <td>24</td>\n","      <td>3.333333</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3401897.75</td>\n","      <td>3438634.25</td>\n","      <td>113911.335938</td>\n","      <td>2467.267578</td>\n","      <td>21</td>\n","      <td>2.916667</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>2947588.25</td>\n","      <td>3004475.00</td>\n","      <td>119564.531250</td>\n","      <td>2989.899170</td>\n","      <td>55</td>\n","      <td>7.638889</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>3119189.50</td>\n","      <td>3156895.50</td>\n","      <td>88695.554688</td>\n","      <td>2125.302002</td>\n","      <td>1</td>\n","      <td>0.138889</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>3348490.75</td>\n","      <td>3368263.00</td>\n","      <td>88905.820312</td>\n","      <td>1928.043091</td>\n","      <td>2</td>\n","      <td>0.277778</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>3920082.25</td>\n","      <td>3928837.00</td>\n","      <td>133205.937500</td>\n","      <td>2531.140381</td>\n","      <td>26</td>\n","      <td>3.611111</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>3705299.25</td>\n","      <td>3763367.50</td>\n","      <td>121135.914062</td>\n","      <td>2489.636230</td>\n","      <td>20</td>\n","      <td>2.777778</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>3223079.00</td>\n","      <td>3263685.50</td>\n","      <td>96946.265625</td>\n","      <td>2161.520264</td>\n","      <td>17</td>\n","      <td>2.361111</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2981794.50</td>\n","      <td>2994979.75</td>\n","      <td>92559.171875</td>\n","      <td>2286.910156</td>\n","      <td>14</td>\n","      <td>1.944444</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>3202975.00</td>\n","      <td>3188765.00</td>\n","      <td>105034.132812</td>\n","      <td>2305.686035</td>\n","      <td>26</td>\n","      <td>3.611111</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3745193.25</td>\n","      <td>3809881.75</td>\n","      <td>144030.437500</td>\n","      <td>2901.099121</td>\n","      <td>55</td>\n","      <td>7.638889</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-64e9a451-8990-4b6c-b8c3-77c24c91ce9f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-64e9a451-8990-4b6c-b8c3-77c24c91ce9f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-64e9a451-8990-4b6c-b8c3-77c24c91ce9f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":78}]},{"cell_type":"code","source":["step_df_grouped['ape_above_10_(%)'].mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m5pNfYMBWkkN","executionInfo":{"status":"ok","timestamp":1681805020294,"user_tz":-180,"elapsed":407,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"28fdfd1f-cd06-4b8d-917a-775d4b2dd38d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3.3217592592592595"]},"metadata":{},"execution_count":79}]}]}