{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["-ab2qm_WcYTh","msgcmWKKKmJS","5VrJ6nvMbK8w","oT2UV0KbpVfW","xYFMj70vqgB7","ILZm7f8Gp5yy","jFsy8i1apr-7","lUHJWjxQqMTa","P279t5OVqvQj","1OXVnN8Xq0cg","xF7JUjfxbfyE","_-fUJquirZ4n","enxRLCopOH2f"],"machine_shape":"hm","toc_visible":true,"gpuType":"T4","authorship_tag":"ABX9TyO5iFGe3H210tKwhTrgpZpr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"e9fc812f2ad443c2af08b3b596f71475":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_997bd4055b8e41648ad328561592276b","IPY_MODEL_cc7553b5f0664036990fc0e066a85597","IPY_MODEL_e154c5f7658448a7aeba7ab29670c268"],"layout":"IPY_MODEL_cb45d0cdf0204320a18ec79531e1f0b9"}},"997bd4055b8e41648ad328561592276b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d79f7f46930c46a68c608180818f3985","placeholder":"​","style":"IPY_MODEL_3bce90f628c340fcbb70de1bdf5e227f","value":" 51%"}},"cc7553b5f0664036990fc0e066a85597":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"danger","description":"","description_tooltip":null,"layout":"IPY_MODEL_5edba41d60d64c61861d2948baafc4e4","max":100,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c70d4541b13e44cd9abadddc6a4ad738","value":51}},"e154c5f7658448a7aeba7ab29670c268":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7f34575c2a2b4f6fb24e926c91224b2f","placeholder":"​","style":"IPY_MODEL_7d38a30c420f41e086a3fc590a6b44de","value":" 51/100 [13:59&lt;13:10, 16.14s/it]"}},"cb45d0cdf0204320a18ec79531e1f0b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d79f7f46930c46a68c608180818f3985":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3bce90f628c340fcbb70de1bdf5e227f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5edba41d60d64c61861d2948baafc4e4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c70d4541b13e44cd9abadddc6a4ad738":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7f34575c2a2b4f6fb24e926c91224b2f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7d38a30c420f41e086a3fc590a6b44de":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Installs + Imports"],"metadata":{"id":"-ab2qm_WcYTh"}},{"cell_type":"code","source":["!pip install pytorch_lightning\n","!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LaQeZBCW-1Sh","executionInfo":{"status":"ok","timestamp":1684953195909,"user_tz":-180,"elapsed":15746,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"4d9077e6-f414-4152-fa7b-41ae021de17b"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.22.4)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.0.1+cu118)\n","Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.65.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.4.0)\n","Collecting torchmetrics>=0.7.0 (from pytorch_lightning)\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n","Collecting lightning-utilities>=0.7.0 (from pytorch_lightning)\n","  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch_lightning)\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.12.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.5)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.12)\n","Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning)\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning)\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning)\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m31.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning)\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning)\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.2)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n","Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch_lightning\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch_lightning-2.0.2 torchmetrics-0.11.4 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: torchmetrics in /usr/local/lib/python3.10/dist-packages (0.11.4)\n","Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.1+cu118)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n"]}]},{"cell_type":"code","source":["import math\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import torch \n","import torch.nn as nn\n","import torch.nn.functional as F\n","import pytorch_lightning as pl\n","\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler, MaxAbsScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.utils import shuffle\n","from google.colab import files\n","from tqdm.auto import tqdm\n","from torchmetrics import MeanAbsolutePercentageError\n","from datetime import datetime \n","from typing import Tuple\n","from functools import partial\n","from torch.optim.lr_scheduler import ReduceLROnPlateau\n","from math import sqrt"],"metadata":{"id":"hrEAsoZx_B8n","executionInfo":{"status":"ok","timestamp":1684953201372,"user_tz":-180,"elapsed":5466,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# Classes + Helpers"],"metadata":{"id":"msgcmWKKKmJS"}},{"cell_type":"markdown","source":["## Data processing"],"metadata":{"id":"5VrJ6nvMbK8w"}},{"cell_type":"code","source":["def scale_data(load_df, \n","               start_train_date,\n","               end_val_date,\n","               start_test_date,\n","               end_test_date):\n","  \n","  train_val_df = load_df[(load_df.index >= start_train_date) &\n","                        (load_df.index <= end_val_date)]\n","  test_df = load_df[(load_df.index >= start_test_date) &\n","                    (load_df.index <= end_test_date)]\n","\n","  scaler = MinMaxScaler()\n","  train_val_scaled = scaler.fit_transform(train_val_df)\n","  train_val_df_scaled = pd.DataFrame(train_val_scaled,\n","                                    columns=train_val_df.columns,\n","                                    index=train_val_df.index)\n","  test_scaled = scaler.transform(test_df)\n","  test_df_scaled = pd.DataFrame(test_scaled,\n","                                columns=test_df.columns,\n","                                index=test_df.index)\n","\n","  load_df_scaled = pd.concat([train_val_df_scaled, test_df_scaled], axis=0)\n","\n","  return load_df_scaled, scaler"],"metadata":{"id":"20DCtZ_EJ8ti","executionInfo":{"status":"ok","timestamp":1684953201956,"user_tz":-180,"elapsed":588,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def reframing_enc(X_df, skip_steps_back, n_backwards):\n","\n","  feat_cols, feat_names = [], []\n","  # iterate through all columns\n","  for col_index, col_name in enumerate(X_df.columns):\n","    series = X_df[col_name].copy()\n","    # input sequence (t-skip_steps_back, ... ,t-(n_backwards+1) )\n","    for b in range(skip_steps_back, n_backwards):\n","      feat_cols.append(series.shift(b))\n","      feat_names.append(f'{col_name}_(t-{b})')\n","  \n","  # put it all together\n","  X = pd.concat(feat_cols, axis=1)\n","  X.columns = feat_names\n","  # drop rows with NaN values\n","  X.dropna(inplace=True)\n","  \n","  return X\n","\n","def reframe_enc_data(load_df_scaled,\n","                     target,\n","                     skip_steps_back,\n","                     last_step_back,\n","                     last_step_forward):\n","\n","  # shift future values\n","  for col in load_df_scaled.drop(target, axis=1).columns:\n","    load_df_scaled[col + f'_(t+{last_step_forward})'] = load_df_scaled[col].shift(-last_step_forward)\n","    load_df_scaled.drop(col, axis=1, inplace=True)\n","\n","  return reframing_enc(load_df_scaled,\n","                       skip_steps_back=skip_steps_back, \n","                       n_backwards=last_step_back)\n","\n","def split_enc_data(load_df_scaled_reframed,\n","                    start_train_date,\n","                    end_train_date,\n","                    start_val_date,\n","                    end_val_date,\n","                    start_test_date,\n","                    end_test_date,\n","                    last_step_back):\n","\n","  load_train_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_train_date) & \n","                                                          (load_df_scaled_reframed.index <= end_train_date)]\n","\n","  load_val_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_val_date) & \n","                                                        (load_df_scaled_reframed.index <= end_val_date)]\n","\n","  load_test_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_test_date) & \n","                                                        (load_df_scaled_reframed.index <= end_test_date)]\n","\n","  X_train_3D = create3Dinput(load_train_df_scaled_reframed, last_step_back)\n","  X_val_3D = create3Dinput(load_val_df_scaled_reframed, last_step_back)\n","  X_test_3D = create3Dinput(load_test_df_scaled_reframed, last_step_back)\n","\n","  return X_train_3D, X_val_3D, X_test_3D"],"metadata":{"id":"lh1YUHYrKTEQ","executionInfo":{"status":"ok","timestamp":1684953201956,"user_tz":-180,"elapsed":9,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def reframing_dec(X_df, n_backwards):\n","\n","  feat_cols, feat_names = [], []\n","  # iterate through all columns\n","  for col_index, col_name in enumerate(X_df.columns):\n","    series = X_df[col_name].copy()\n","    # input sequence (t, t-1, ... ,t-(n_backwards+1) )\n","    for b in range(n_backwards):\n","      feat_cols.append(series.shift(b))\n","      feat_names.append(f'{col_name}_(t-{b})')\n","  \n","  # put it all together\n","  X = pd.concat(feat_cols, axis=1)\n","  X.columns = feat_names\n","  # drop rows with NaN values\n","  X.dropna(inplace=True)\n","  \n","  return X\n","\n","def reframe_dec_data(load_df_scaled,\n","                     last_step_back,\n","                     last_step_forward):\n","\n","  # shift future values (weather + time data)\n","  for col in load_df_scaled.columns:\n","    load_df_scaled[col + f'_(t+{last_step_forward})'] = load_df_scaled[col].shift(-last_step_forward)\n","    load_df_scaled.drop(col, axis=1, inplace=True)\n","\n","  return reframing_dec(load_df_scaled, \n","                       n_backwards=last_step_back + last_step_forward)\n","\n","def split_dec_data(load_df_scaled_reframed,\n","                    start_train_date,\n","                    end_train_date,\n","                    start_val_date,\n","                    end_val_date,\n","                    start_test_date,\n","                    end_test_date,\n","                    steps_forward,\n","                    last_step_back):\n","\n","  load_train_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_train_date) & \n","                                                          (load_df_scaled_reframed.index <= end_train_date)]\n","\n","  load_val_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_val_date) & \n","                                                        (load_df_scaled_reframed.index <= end_val_date)]\n","\n","  load_test_df_scaled_reframed = load_df_scaled_reframed[(load_df_scaled_reframed.index >= start_test_date) & \n","                                                        (load_df_scaled_reframed.index <= end_test_date)]\n","\n","  X_train_3D = create3Dinput(load_train_df_scaled_reframed, last_step_back+steps_forward)\n","  X_val_3D = create3Dinput(load_val_df_scaled_reframed, last_step_back+steps_forward)\n","  X_test_3D = create3Dinput(load_test_df_scaled_reframed, last_step_back+steps_forward)\n","\n","  return X_train_3D, X_val_3D, X_test_3D"],"metadata":{"id":"Yh-T9vcBS-kD","executionInfo":{"status":"ok","timestamp":1684953201956,"user_tz":-180,"elapsed":9,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def create3Dinput(df, steps):\n","  N, D = df.shape\n","  D = int(D/steps)\n","  arr_3d = np.zeros((N, steps, D))\n","  for i in range(D):\n","    arr_3d[:, :, i] = df.iloc[:, i*steps:(i+1)*steps].values\n","  print(arr_3d.shape)\n","  return arr_3d\n","\n","class LoadDataset(Dataset):\n","  def __init__(self, X_3D_enc, X_3D_time_enc, X_3D_dec, X_3D_time_dec, y):\n","    self.X_enc = torch.tensor(X_3D_enc, dtype=torch.float32)\n","    self.X_time_enc = torch.tensor(X_3D_time_enc, dtype=torch.float32)\n","    self.X_dec = torch.tensor(X_3D_dec, dtype=torch.float32)\n","    self.X_time_dec = torch.tensor(X_3D_time_dec, dtype=torch.float32)\n","    self.y = torch.tensor(y, dtype=torch.float32)\n","  \n","  def __len__(self):\n","    return len(self.y)\n","\n","  def __getitem__(self, idx):\n","    return self.X_enc[idx], self.X_time_enc[idx], self.X_dec[idx], self.X_time_dec[idx], self.y[idx]"],"metadata":{"id":"V-8n4sGJKgGw","executionInfo":{"status":"ok","timestamp":1684953201957,"user_tz":-180,"elapsed":10,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["## Informer class"],"metadata":{"id":"oT2UV0KbpVfW"}},{"cell_type":"markdown","source":["### Embeddings"],"metadata":{"id":"xYFMj70vqgB7"}},{"cell_type":"code","source":["class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        minute_size = 4; hour_size = 24\n","        weekday_size = 7; day_size = 32; month_size = 13\n","\n","        Embed = FixedEmbedding if embed_type=='fixed' else nn.Embedding\n","        if freq=='t':\n","            self.minute_embed = Embed(minute_size, d_model)\n","        self.hour_embed = Embed(hour_size, d_model)\n","        self.weekday_embed = Embed(weekday_size, d_model)\n","        self.day_embed = Embed(day_size, d_model)\n","        self.month_embed = Embed(month_size, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        minute_x = self.minute_embed(x[:,:,4]) if hasattr(self, 'minute_embed') else 0.\n","        # print(f\"minute_x --> {minute_x}\")\n","        hour_x = self.hour_embed(x[:,:,3])\n","        # print(f\"hour_x --> {hour_x.shape}\")\n","        weekday_x = self.weekday_embed(x[:,:,2])\n","        # print(f\"weekday_x --> {weekday_x.shape}\")\n","        day_x = self.day_embed(x[:,:,1])\n","        # print(f\"day_x --> {day_x.shape}\")\n","        month_x = self.month_embed(x[:,:,0])\n","        # print(f\"month_x --> {month_x.shape}\")\n","        \n","        return hour_x + weekday_x + day_x + month_x + minute_x\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'h':4, 't':5, 's':6, 'm':1, 'a':1, 'w':2, 'd':3, 'b':3}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='fixed', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"],"metadata":{"id":"7JgJwHuBqkoZ","executionInfo":{"status":"ok","timestamp":1684953201957,"user_tz":-180,"elapsed":9,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["### Masking"],"metadata":{"id":"ILZm7f8Gp5yy"}},{"cell_type":"code","source":["class TriangularCausalMask():\n","    def __init__(self, B, L, device=\"cpu\"):\n","        mask_shape = [B, 1, L, L]\n","        with torch.no_grad():\n","            self._mask = torch.triu(torch.ones(mask_shape, dtype=torch.bool), diagonal=1).to(device)\n","\n","    @property\n","    def mask(self):\n","        return self._mask\n","\n","class ProbMask():\n","    def __init__(self, B, H, L, index, scores, device=\"cpu\"):\n","        _mask = torch.ones(L, scores.shape[-1], dtype=torch.bool).to(device).triu(1)\n","        _mask_ex = _mask[None, None, :].expand(B, H, L, scores.shape[-1])\n","        indicator = _mask_ex[torch.arange(B)[:, None, None],\n","                             torch.arange(H)[None, :, None],\n","                             index, :].to(device)\n","        self._mask = indicator.view(scores.shape).to(device)\n","    \n","    @property\n","    def mask(self):\n","        return self._mask"],"metadata":{"id":"81v845Ebp9D5","executionInfo":{"status":"ok","timestamp":1684953201957,"user_tz":-180,"elapsed":8,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Attention"],"metadata":{"id":"jFsy8i1apr-7"}},{"cell_type":"code","source":["class FullAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(FullAttention, self).__init__()\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","        \n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, H, E = queries.shape\n","        _, S, _, D = values.shape\n","        scale = self.scale or 1./sqrt(E)\n","\n","        scores = torch.einsum(\"blhe,bshe->bhls\", queries, keys)\n","        if self.mask_flag:\n","            if attn_mask is None:\n","                attn_mask = TriangularCausalMask(B, L, device=queries.device)\n","\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        A = self.dropout(torch.softmax(scale * scores, dim=-1))\n","        V = torch.einsum(\"bhls,bshd->blhd\", A, values)\n","        \n","        if self.output_attention:\n","            return (V.contiguous(), A)\n","        else:\n","            return (V.contiguous(), None)\n","\n","class ProbAttention(nn.Module):\n","    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1, output_attention=False):\n","        super(ProbAttention, self).__init__()\n","        self.factor = factor\n","        self.scale = scale\n","        self.mask_flag = mask_flag\n","        self.output_attention = output_attention\n","        self.dropout = nn.Dropout(attention_dropout)\n","\n","    def _prob_QK(self, Q, K, sample_k, n_top): # n_top: c*ln(L_q)\n","        # Q [B, H, L, D]\n","        B, H, L_K, E = K.shape\n","        _, _, L_Q, _ = Q.shape\n","\n","        # calculate the sampled Q_K\n","        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n","        index_sample = torch.randint(L_K, (L_Q, sample_k)) # real U = U_part(factor*ln(L_k))*L_q\n","        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n","        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n","\n","        # find the Top_k query with sparisty measurement\n","        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n","        M_top = M.topk(n_top, sorted=False)[1]\n","\n","        # use the reduced Q to calculate Q_K\n","        Q_reduce = Q[torch.arange(B)[:, None, None],\n","                     torch.arange(H)[None, :, None],\n","                     M_top, :] # factor*ln(L_q)\n","        Q_K = torch.matmul(Q_reduce, K.transpose(-2, -1)) # factor*ln(L_q)*L_k\n","\n","        return Q_K, M_top\n","\n","    def _get_initial_context(self, V, L_Q):\n","        B, H, L_V, D = V.shape\n","        if not self.mask_flag:\n","            # V_sum = V.sum(dim=-2)\n","            V_sum = V.mean(dim=-2)\n","            contex = V_sum.unsqueeze(-2).expand(B, H, L_Q, V_sum.shape[-1]).clone()\n","        else: # use mask\n","            assert(L_Q == L_V) # requires that L_Q == L_V, i.e. for self-attention only\n","            contex = V.cumsum(dim=-2)\n","        return contex\n","\n","    def _update_context(self, context_in, V, scores, index, L_Q, attn_mask):\n","        B, H, L_V, D = V.shape\n","\n","        if self.mask_flag:\n","            attn_mask = ProbMask(B, H, L_Q, index, scores, device=V.device)\n","            scores.masked_fill_(attn_mask.mask, -np.inf)\n","\n","        attn = torch.softmax(scores, dim=-1) # nn.Softmax(dim=-1)(scores)\n","\n","        context_in[torch.arange(B)[:, None, None],\n","                   torch.arange(H)[None, :, None],\n","                   index, :] = torch.matmul(attn, V).type_as(context_in)\n","        if self.output_attention:\n","            attns = (torch.ones([B, H, L_V, L_V])/L_V).type_as(attn).to(attn.device)\n","            attns[torch.arange(B)[:, None, None], torch.arange(H)[None, :, None], index, :] = attn\n","            return (context_in, attns)\n","        else:\n","            return (context_in, None)\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L_Q, H, D = queries.shape\n","        _, L_K, _, _ = keys.shape\n","\n","        queries = queries.transpose(2,1)\n","        keys = keys.transpose(2,1)\n","        values = values.transpose(2,1)\n","\n","        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item() # c*ln(L_k)\n","        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item() # c*ln(L_q) \n","\n","        U_part = U_part if U_part<L_K else L_K\n","        u = u if u<L_Q else L_Q\n","        \n","        scores_top, index = self._prob_QK(queries, keys, sample_k=U_part, n_top=u) \n","\n","        # add scale factor\n","        scale = self.scale or 1./sqrt(D)\n","        if scale is not None:\n","            scores_top = scores_top * scale\n","        # get the context\n","        context = self._get_initial_context(values, L_Q)\n","        # update the context with selected top_k queries\n","        context, attn = self._update_context(context, values, scores_top, index, L_Q, attn_mask)\n","        \n","        return context.transpose(2,1).contiguous(), attn\n","\n","\n","class AttentionLayer(nn.Module):\n","    def __init__(self, attention, d_model, n_heads, \n","                 d_keys=None, d_values=None, mix=False):\n","        super(AttentionLayer, self).__init__()\n","\n","        d_keys = d_keys or (d_model//n_heads)\n","        d_values = d_values or (d_model//n_heads)\n","\n","        self.inner_attention = attention\n","        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n","        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n","        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n","        self.n_heads = n_heads\n","        self.mix = mix\n","\n","    def forward(self, queries, keys, values, attn_mask):\n","        B, L, _ = queries.shape\n","        _, S, _ = keys.shape\n","        H = self.n_heads\n","\n","        queries = self.query_projection(queries).view(B, L, H, -1)\n","        keys = self.key_projection(keys).view(B, S, H, -1)\n","        values = self.value_projection(values).view(B, S, H, -1)\n","\n","        out, attn = self.inner_attention(\n","            queries,\n","            keys,\n","            values,\n","            attn_mask\n","        )\n","        if self.mix:\n","            out = out.transpose(2,1).contiguous()\n","        out = out.view(B, L, -1)\n","\n","        return self.out_projection(out), attn"],"metadata":{"id":"XU0tZNvepS6k","executionInfo":{"status":"ok","timestamp":1684953201957,"user_tz":-180,"elapsed":8,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### Encoder"],"metadata":{"id":"lUHJWjxQqMTa"}},{"cell_type":"code","source":["class ConvLayer(nn.Module):\n","    def __init__(self, c_in):\n","        super(ConvLayer, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.downConv = nn.Conv1d(in_channels=c_in,\n","                                  out_channels=c_in,\n","                                  kernel_size=3,\n","                                  padding=padding,\n","                                  padding_mode='circular')\n","        self.norm = nn.BatchNorm1d(c_in)\n","        self.activation = nn.ELU()\n","        self.maxPool = nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n","\n","    def forward(self, x):\n","        x = self.downConv(x.permute(0, 2, 1))\n","        x = self.norm(x)\n","        x = self.activation(x)\n","        x = self.maxPool(x)\n","        x = x.transpose(1,2)\n","        return x\n","\n","class EncoderLayer(nn.Module):\n","    def __init__(self, attention, d_model, d_ff=None, dropout=0.1, activation=\"relu\"):\n","        super(EncoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.attention = attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        # x = x + self.dropout(self.attention(\n","        #     x, x, x,\n","        #     attn_mask = attn_mask\n","        # ))\n","        new_x, attn = self.attention(\n","            x, x, x,\n","            attn_mask = attn_mask\n","        )\n","        x = x + self.dropout(new_x)\n","\n","        y = x = self.norm1(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm2(x+y), attn\n","\n","class Encoder(nn.Module):\n","    def __init__(self, attn_layers, conv_layers=None, norm_layer=None):\n","        super(Encoder, self).__init__()\n","        self.attn_layers = nn.ModuleList(attn_layers)\n","        self.conv_layers = nn.ModuleList(conv_layers) if conv_layers is not None else None\n","        self.norm = norm_layer\n","\n","    def forward(self, x, attn_mask=None):\n","        # x [B, L, D]\n","        attns = []\n","        if self.conv_layers is not None:\n","            for attn_layer, conv_layer in zip(self.attn_layers, self.conv_layers):\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                x = conv_layer(x)\n","                attns.append(attn)\n","            x, attn = self.attn_layers[-1](x, attn_mask=attn_mask)\n","            attns.append(attn)\n","        else:\n","            for attn_layer in self.attn_layers:\n","                x, attn = attn_layer(x, attn_mask=attn_mask)\n","                attns.append(attn)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x, attns"],"metadata":{"id":"vE0xlwNVqoXm","executionInfo":{"status":"ok","timestamp":1684953201957,"user_tz":-180,"elapsed":7,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Decoder"],"metadata":{"id":"P279t5OVqvQj"}},{"cell_type":"code","source":["class DecoderLayer(nn.Module):\n","    def __init__(self, self_attention, cross_attention, d_model, d_ff=None,\n","                 dropout=0.1, activation=\"relu\"):\n","        super(DecoderLayer, self).__init__()\n","        d_ff = d_ff or 4*d_model\n","        self.self_attention = self_attention\n","        self.cross_attention = cross_attention\n","        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n","        self.norm1 = nn.LayerNorm(d_model)\n","        self.norm2 = nn.LayerNorm(d_model)\n","        self.norm3 = nn.LayerNorm(d_model)\n","        self.dropout = nn.Dropout(dropout)\n","        self.activation = F.relu if activation == \"relu\" else F.gelu\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        x = x + self.dropout(self.self_attention(\n","            x, x, x,\n","            attn_mask=x_mask\n","        )[0])\n","        x = self.norm1(x)\n","\n","        x = x + self.dropout(self.cross_attention(\n","            x, cross, cross,\n","            attn_mask=cross_mask\n","        )[0])\n","\n","        y = x = self.norm2(x)\n","        y = self.dropout(self.activation(self.conv1(y.transpose(-1,1))))\n","        y = self.dropout(self.conv2(y).transpose(-1,1))\n","\n","        return self.norm3(x+y)\n","\n","class Decoder(nn.Module):\n","    def __init__(self, layers, norm_layer=None):\n","        super(Decoder, self).__init__()\n","        self.layers = nn.ModuleList(layers)\n","        self.norm = norm_layer\n","\n","    def forward(self, x, cross, x_mask=None, cross_mask=None):\n","        for layer in self.layers:\n","            x = layer(x, cross, x_mask=x_mask, cross_mask=cross_mask)\n","\n","        if self.norm is not None:\n","            x = self.norm(x)\n","\n","        return x"],"metadata":{"id":"iV6yc8C5qwV5","executionInfo":{"status":"ok","timestamp":1684953201957,"user_tz":-180,"elapsed":7,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["### Informer"],"metadata":{"id":"1OXVnN8Xq0cg"}},{"cell_type":"code","source":["class Informer(nn.Module):\n","    def __init__(self, enc_in, dec_in, c_out, out_len,\n","                factor=5, d_model=512, n_heads=8, e_layers=3, d_layers=2, d_ff=512, \n","                dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu', \n","                output_attention = False, distil=True, mix=True,\n","                device=torch.device('cuda:0')):\n","        super(Informer, self).__init__()\n","        self.pred_len = out_len\n","        self.attn = attn\n","        self.output_attention = output_attention\n","\n","        # Encoding\n","        self.enc_embedding = DataEmbedding(enc_in, d_model, embed, freq, dropout)\n","        self.dec_embedding = DataEmbedding(dec_in, d_model, embed, freq, dropout)\n","        # Attention\n","        Attn = ProbAttention if attn=='prob' else FullAttention\n","        # Encoder\n","        self.encoder = Encoder(\n","            [\n","                EncoderLayer(\n","                    AttentionLayer(Attn(False, factor, attention_dropout=dropout, output_attention=output_attention), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation\n","                ) for l in range(e_layers)\n","            ],\n","            [\n","                ConvLayer(\n","                    d_model\n","                ) for l in range(e_layers-1)\n","            ] if distil else None,\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # Decoder\n","        self.decoder = Decoder(\n","            [\n","                DecoderLayer(\n","                    AttentionLayer(Attn(True, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=mix),\n","                    AttentionLayer(FullAttention(False, factor, attention_dropout=dropout, output_attention=False), \n","                                d_model, n_heads, mix=False),\n","                    d_model,\n","                    d_ff,\n","                    dropout=dropout,\n","                    activation=activation,\n","                )\n","                for l in range(d_layers)\n","            ],\n","            norm_layer=torch.nn.LayerNorm(d_model)\n","        )\n","        # self.end_conv1 = nn.Conv1d(in_channels=label_len+out_len, out_channels=out_len, kernel_size=1, bias=True)\n","        # self.end_conv2 = nn.Conv1d(in_channels=d_model, out_channels=c_out, kernel_size=1, bias=True)\n","        self.projection = nn.Linear(d_model, c_out, bias=True)\n","        \n","    def forward(self, x_enc, x_mark_enc, x_dec, x_mark_dec, \n","                enc_self_mask=None, dec_self_mask=None, dec_enc_mask=None):\n","        enc_out = self.enc_embedding(x_enc, x_mark_enc)\n","        enc_out, attns = self.encoder(enc_out, attn_mask=enc_self_mask)\n","\n","        dec_out = self.dec_embedding(x_dec, x_mark_dec)\n","        dec_out = self.decoder(dec_out, enc_out, x_mask=dec_self_mask, cross_mask=dec_enc_mask)\n","        dec_out = self.projection(dec_out)\n","        \n","        # dec_out = self.end_conv1(dec_out)\n","        # dec_out = self.end_conv2(dec_out.transpose(2,1)).transpose(1,2)\n","        if self.output_attention:\n","            return dec_out[:,-self.pred_len:,:], attns\n","        else:\n","            return dec_out[:,-self.pred_len:,:] # [B, L, D]"],"metadata":{"id":"9eXJMbtFq1zh","executionInfo":{"status":"ok","timestamp":1684953201957,"user_tz":-180,"elapsed":7,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["## Training and Evaluation"],"metadata":{"id":"xF7JUjfxbfyE"}},{"cell_type":"code","source":["def train_step(model,\n","               dataloader, \n","               optimizer, \n","               loss_fn,\n","               device):\n","  \n","  model.train()\n","  loss = 0\n","  for batch, (X_enc, X_time_enc, X_dec, X_time_dec, Y) in enumerate(dataloader):\n","    X_enc, X_time_enc, X_dec, X_time_dec, Y = X_enc.to(device), X_time_enc.to(device), X_dec.to(device), X_time_dec.to(device), Y.to(device)\n","    Y_preds = model(x_enc=X_enc, x_mark_enc=X_time_enc, x_dec=X_dec, x_mark_dec=X_time_dec).squeeze()\n","    batch_loss = loss_fn(Y_preds, Y) \n","    loss += batch_loss.item()\n","    optimizer.zero_grad()\n","    batch_loss.backward()\n","    optimizer.step()\n","  \n","  loss /= len(dataloader)\n","  return loss\n","\n","def val_step(model, dataloader, loss_fn, device):\n","  model.eval()\n","  val_loss = 0\n","  with torch.inference_mode():\n","    for batch, (X_enc, X_time_enc, X_dec, X_time_dec, Y) in enumerate(dataloader):\n","      X_enc, X_time_enc, X_dec, X_time_dec, Y = X_enc.to(device), X_time_enc.to(device), X_dec.to(device), X_time_dec.to(device), Y.to(device)\n","      Y_preds = model(x_enc=X_enc, x_mark_enc=X_time_enc, x_dec=X_dec, x_mark_dec=X_time_dec).squeeze()\n","      batch_loss = loss_fn(Y_preds, Y) \n","      val_loss += batch_loss.item()\n","  \n","  val_loss /= len(dataloader)\n","  return val_loss\n","\n","def train(model, \n","          train_dataloader,\n","          val_dataloader,\n","          optimizer,\n","          scheduler,\n","          loss_fn,\n","          epochs,\n","          patience,\n","          device,\n","          path):\n","  \n","  results = {\n","      \"loss\": [],\n","      \"val_loss\": []\n","  }\n","\n","  for epoch in tqdm(range(epochs)):\n","    flag = 0\n","    loss = train_step(model=model,\n","                      dataloader=train_dataloader,\n","                      optimizer=optimizer,\n","                      loss_fn=loss_fn,\n","                      device=device)\n","\n","    val_loss = val_step(model=model,\n","                        dataloader=val_dataloader,\n","                        loss_fn=loss_fn,\n","                        device=device)\n","    scheduler.step(val_loss)\n","    \n","    results['loss'].append(loss)\n","    results['val_loss'].append(val_loss)\n","    if epoch == 0:\n","      best_val_loss = val_loss\n","      best_epoch = -1\n","      checkpoint(model, optimizer, path)\n","      flag = 1\n","      print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f} - *Checkpoint*\")\n","    else:\n","      if val_loss < best_val_loss:\n","        best_val_loss = val_loss\n","        best_epoch = epoch\n","        checkpoint(model, optimizer, path)\n","        flag = 1\n","        print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f} - *Checkpoint*\")\n","      elif epoch - best_epoch > patience:\n","        print(f\"\\nEarly stopping applied at epoch {epoch}.\")\n","        break\n","    if flag == 0:\n","      print(f\"Epoch: {epoch+1}/{epochs} | Loss: {loss:.4f} | Val loss: {val_loss:.4f}\")\n","  \n","  return results\n","\n","def checkpoint(model, optimizer, filepath):\n","  torch.save({\n","    \"optimizer\": optimizer.state_dict(),\n","    \"model\": model.state_dict()\n","  }, filepath)"],"metadata":{"id":"s2egVAsMZW6Z","executionInfo":{"status":"ok","timestamp":1684953201958,"user_tz":-180,"elapsed":7,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["# Test Informer class"],"metadata":{"id":"_-fUJquirZ4n"}},{"cell_type":"code","source":["x = torch.tensor(np.random.randn(8, 7, 5), dtype=torch.float32)\n","x_mark = torch.tensor(np.random.rand(8, 7, 4), dtype=torch.float32)\n","\n","de = DataEmbedding(c_in=5, d_model=64)\n","y = de(x, x_mark)\n","\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cLLjGxIUrb_2","executionInfo":{"status":"ok","timestamp":1681591438373,"user_tz":-180,"elapsed":15,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"fef67a02-b13e-4561-db15-856c6b103105"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 7, 64])\n"]}]},{"cell_type":"code","source":["x_enc = torch.tensor(np.random.randn(8, 7*24, 9), dtype=torch.float32)\n","x_mark_enc = torch.tensor(np.random.rand(8, 7*24, 4), dtype=torch.float32)\n","\n","x_dec = torch.tensor(np.random.randn(8, 14*24, 9), dtype=torch.float32)\n","x_mark_dec = torch.tensor(np.random.rand(8, 14*24, 4), dtype=torch.float32)\n","\n","informer = Informer(enc_in=9, dec_in=9, c_out=24, out_len=1)\n","y = informer(x_enc, x_mark_enc, x_dec, x_mark_dec)\n","\n","print(y.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uBfyiMFx0RDN","executionInfo":{"status":"ok","timestamp":1681591440147,"user_tz":-180,"elapsed":1788,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"999a76d3-1943-4f34-e943-01bd20d3a26d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([8, 1, 24])\n"]}]},{"cell_type":"code","source":["# informer.state_dict"],"metadata":{"id":"xkohdbMjOKSt"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# MAIN"],"metadata":{"id":"enxRLCopOH2f"}},{"cell_type":"code","source":["# Encoder \n","DAYS_BACK_ENC = 2\n","SKIP_DAYS_BACK_ENC = 2\n","SKIP_STEPS_BACK_ENC = 24 * SKIP_DAYS_BACK_ENC\n","STEPS_BACK_ENC = 24 * DAYS_BACK_ENC\n","LAST_STEP_BACK_ENC = STEPS_BACK_ENC + SKIP_STEPS_BACK_ENC\n","\n","# Decoder\n","DAYS_BACK_DEC = 2\n","LAST_STEP_BACK_DEC = 24 * DAYS_BACK_DEC\n","\n","# Forward\n","DAYS_TO_SKIP = 0\n","STEPS_FORWARD = 24    # 1 day\n","SKIP_STEPS_FORWARD = 24 * DAYS_TO_SKIP\n","LAST_STEP_FORWARD = STEPS_FORWARD + SKIP_STEPS_FORWARD\n","\n","# keep 1 year for testing\n","START_TEST_DATE = pd.to_datetime('2018-01-01') - pd.to_timedelta(SKIP_STEPS_FORWARD+1, 'h')\n","END_TEST_DATE = START_TEST_DATE + pd.DateOffset(years=1)\n","\n","END_VAL_DATE = START_TEST_DATE - pd.to_timedelta(1, 'h')\n","START_VAL_DATE = pd.to_datetime('2017-01-01') - pd.to_timedelta(LAST_STEP_FORWARD, 'h')\n","\n","# START_TRAIN_DATE = pd.to_datetime('2016-01-01')\n","START_TRAIN_DATE = pd.to_datetime('2010-10-01')\n","END_TRAIN_DATE = START_VAL_DATE - pd.to_timedelta(1, 'h')\n","\n","TARGET = \"TOTAL_CONS\"\n","\n","BATCH_SIZE = 1024\n","EPOCHS = 1000\n","PATIENCE = 15\n","PATH = \"model.pth\"\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","print(f\"Train from {START_TRAIN_DATE} to {END_TRAIN_DATE}\")\n","print(f\"Validation from {START_VAL_DATE} to {END_VAL_DATE}\")\n","print(f\"Test from {START_TEST_DATE} to {END_TEST_DATE}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XIWtO-IO55LI","executionInfo":{"status":"ok","timestamp":1684953272240,"user_tz":-180,"elapsed":433,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"5e468872-dde5-4504-9ec1-db6703d24ffe"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Train from 2010-10-01 00:00:00 to 2016-12-30 23:00:00\n","Validation from 2016-12-31 00:00:00 to 2017-12-31 22:00:00\n","Test from 2017-12-31 23:00:00 to 2018-12-31 23:00:00\n"]}]},{"cell_type":"code","source":["data_df = pd.read_csv(\"/content/FINAL_DATASET_2.csv\")\n","data_df.set_index(pd.to_datetime(data_df[\"Timestamp\"]), inplace=True)\n","data_df.drop(\"Timestamp\", axis=1, inplace=True)\n","\n","TARGET_POS = np.where(data_df.columns == TARGET)[0][0]\n","TIME_COLS = list(data_df.drop([TARGET, 'temp', 'humidity'], axis=1).columns)\n","TIME_POS = list(np.where(data_df.columns == col)[0][0] for col in TIME_COLS)\n","\n","data_df_scaled, scaler = scale_data(data_df,\n","                                    START_TRAIN_DATE,\n","                                    END_VAL_DATE,\n","                                    START_TEST_DATE,\n","                                    END_TEST_DATE)"],"metadata":{"id":"zkUivavC7G2g","executionInfo":{"status":"ok","timestamp":1684953272241,"user_tz":-180,"elapsed":4,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["data_df_scaled_reframed_enc = reframe_enc_data(data_df_scaled.copy(), \n","                                               TARGET,\n","                                               SKIP_STEPS_BACK_ENC,\n","                                               LAST_STEP_BACK_ENC,\n","                                               LAST_STEP_FORWARD)\n","\n","data_df_scaled_reframed_dec = reframe_dec_data(data_df_scaled.copy(),\n","                                               LAST_STEP_BACK_DEC,\n","                                               LAST_STEP_FORWARD)\n","\n","common_index = data_df_scaled_reframed_enc.index.intersection(data_df_scaled_reframed_dec.index)\n","data_df_scaled_reframed_enc = data_df_scaled_reframed_enc.loc[common_index]\n","data_df_scaled_reframed_dec = data_df_scaled_reframed_dec.loc[common_index]\n","\n","print(data_df_scaled_reframed_enc.shape, data_df_scaled_reframed_dec.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NIwCutXoQZZ1","executionInfo":{"status":"ok","timestamp":1684953273284,"user_tz":-180,"elapsed":1047,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"845e8b68-24ca-4134-b0d3-e21c5b967e05"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["(72217, 384) (72217, 576)\n"]}]},{"cell_type":"code","source":["data_df_scaled_reframed_enc.iloc[:5, :7*24 + 1]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"ojMt6_MQUp3R","executionInfo":{"status":"ok","timestamp":1684953273285,"user_tz":-180,"elapsed":5,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"87515486-e0f1-464f-edb4-a26f6addf198"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                     TOTAL_CONS_(t-48)  TOTAL_CONS_(t-49)  TOTAL_CONS_(t-50)  \\\n","Timestamp                                                                      \n","2010-10-04 23:00:00           0.258913           0.314062           0.385122   \n","2010-10-05 00:00:00           0.202129           0.258913           0.314062   \n","2010-10-05 01:00:00           0.149220           0.202129           0.258913   \n","2010-10-05 02:00:00           0.124180           0.149220           0.202129   \n","2010-10-05 03:00:00           0.109828           0.124180           0.149220   \n","\n","                     TOTAL_CONS_(t-51)  TOTAL_CONS_(t-52)  TOTAL_CONS_(t-53)  \\\n","Timestamp                                                                      \n","2010-10-04 23:00:00           0.443153           0.403555           0.310807   \n","2010-10-05 00:00:00           0.385122           0.443153           0.403555   \n","2010-10-05 01:00:00           0.314062           0.385122           0.443153   \n","2010-10-05 02:00:00           0.258913           0.314062           0.385122   \n","2010-10-05 03:00:00           0.202129           0.258913           0.314062   \n","\n","                     TOTAL_CONS_(t-54)  TOTAL_CONS_(t-55)  TOTAL_CONS_(t-56)  \\\n","Timestamp                                                                      \n","2010-10-04 23:00:00           0.278349           0.263831           0.290594   \n","2010-10-05 00:00:00           0.310807           0.278349           0.263831   \n","2010-10-05 01:00:00           0.403555           0.310807           0.278349   \n","2010-10-05 02:00:00           0.443153           0.403555           0.310807   \n","2010-10-05 03:00:00           0.385122           0.443153           0.403555   \n","\n","                     TOTAL_CONS_(t-57)  ...  temp_(t+24)_(t-63)  \\\n","Timestamp                               ...                       \n","2010-10-04 23:00:00           0.349173  ...            0.429971   \n","2010-10-05 00:00:00           0.290594  ...            0.478967   \n","2010-10-05 01:00:00           0.263831  ...            0.557839   \n","2010-10-05 02:00:00           0.278349  ...            0.614245   \n","2010-10-05 03:00:00           0.310807  ...            0.642208   \n","\n","                     temp_(t+24)_(t-64)  temp_(t+24)_(t-65)  \\\n","Timestamp                                                     \n","2010-10-04 23:00:00            0.426386            0.431166   \n","2010-10-05 00:00:00            0.429971            0.426386   \n","2010-10-05 01:00:00            0.478967            0.429971   \n","2010-10-05 02:00:00            0.557839            0.478967   \n","2010-10-05 03:00:00            0.614245            0.557839   \n","\n","                     temp_(t+24)_(t-66)  temp_(t+24)_(t-67)  \\\n","Timestamp                                                     \n","2010-10-04 23:00:00            0.470124            0.462715   \n","2010-10-05 00:00:00            0.431166            0.470124   \n","2010-10-05 01:00:00            0.426386            0.431166   \n","2010-10-05 02:00:00            0.429971            0.426386   \n","2010-10-05 03:00:00            0.478967            0.429971   \n","\n","                     temp_(t+24)_(t-68)  temp_(t+24)_(t-69)  \\\n","Timestamp                                                     \n","2010-10-04 23:00:00            0.472036            0.475382   \n","2010-10-05 00:00:00            0.462715            0.472036   \n","2010-10-05 01:00:00            0.470124            0.462715   \n","2010-10-05 02:00:00            0.431166            0.470124   \n","2010-10-05 03:00:00            0.426386            0.431166   \n","\n","                     temp_(t+24)_(t-70)  temp_(t+24)_(t-71)  \\\n","Timestamp                                                     \n","2010-10-04 23:00:00            0.494742            0.518881   \n","2010-10-05 00:00:00            0.475382            0.494742   \n","2010-10-05 01:00:00            0.472036            0.475382   \n","2010-10-05 02:00:00            0.462715            0.472036   \n","2010-10-05 03:00:00            0.470124            0.462715   \n","\n","                     temp_(t+24)_(t-72)  \n","Timestamp                                \n","2010-10-04 23:00:00            0.521750  \n","2010-10-05 00:00:00            0.518881  \n","2010-10-05 01:00:00            0.494742  \n","2010-10-05 02:00:00            0.475382  \n","2010-10-05 03:00:00            0.472036  \n","\n","[5 rows x 169 columns]"],"text/html":["\n","  <div id=\"df-2becf8c7-49fc-4b01-99f8-c56e71f094dc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>TOTAL_CONS_(t-48)</th>\n","      <th>TOTAL_CONS_(t-49)</th>\n","      <th>TOTAL_CONS_(t-50)</th>\n","      <th>TOTAL_CONS_(t-51)</th>\n","      <th>TOTAL_CONS_(t-52)</th>\n","      <th>TOTAL_CONS_(t-53)</th>\n","      <th>TOTAL_CONS_(t-54)</th>\n","      <th>TOTAL_CONS_(t-55)</th>\n","      <th>TOTAL_CONS_(t-56)</th>\n","      <th>TOTAL_CONS_(t-57)</th>\n","      <th>...</th>\n","      <th>temp_(t+24)_(t-63)</th>\n","      <th>temp_(t+24)_(t-64)</th>\n","      <th>temp_(t+24)_(t-65)</th>\n","      <th>temp_(t+24)_(t-66)</th>\n","      <th>temp_(t+24)_(t-67)</th>\n","      <th>temp_(t+24)_(t-68)</th>\n","      <th>temp_(t+24)_(t-69)</th>\n","      <th>temp_(t+24)_(t-70)</th>\n","      <th>temp_(t+24)_(t-71)</th>\n","      <th>temp_(t+24)_(t-72)</th>\n","    </tr>\n","    <tr>\n","      <th>Timestamp</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2010-10-04 23:00:00</th>\n","      <td>0.258913</td>\n","      <td>0.314062</td>\n","      <td>0.385122</td>\n","      <td>0.443153</td>\n","      <td>0.403555</td>\n","      <td>0.310807</td>\n","      <td>0.278349</td>\n","      <td>0.263831</td>\n","      <td>0.290594</td>\n","      <td>0.349173</td>\n","      <td>...</td>\n","      <td>0.429971</td>\n","      <td>0.426386</td>\n","      <td>0.431166</td>\n","      <td>0.470124</td>\n","      <td>0.462715</td>\n","      <td>0.472036</td>\n","      <td>0.475382</td>\n","      <td>0.494742</td>\n","      <td>0.518881</td>\n","      <td>0.521750</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-05 00:00:00</th>\n","      <td>0.202129</td>\n","      <td>0.258913</td>\n","      <td>0.314062</td>\n","      <td>0.385122</td>\n","      <td>0.443153</td>\n","      <td>0.403555</td>\n","      <td>0.310807</td>\n","      <td>0.278349</td>\n","      <td>0.263831</td>\n","      <td>0.290594</td>\n","      <td>...</td>\n","      <td>0.478967</td>\n","      <td>0.429971</td>\n","      <td>0.426386</td>\n","      <td>0.431166</td>\n","      <td>0.470124</td>\n","      <td>0.462715</td>\n","      <td>0.472036</td>\n","      <td>0.475382</td>\n","      <td>0.494742</td>\n","      <td>0.518881</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-05 01:00:00</th>\n","      <td>0.149220</td>\n","      <td>0.202129</td>\n","      <td>0.258913</td>\n","      <td>0.314062</td>\n","      <td>0.385122</td>\n","      <td>0.443153</td>\n","      <td>0.403555</td>\n","      <td>0.310807</td>\n","      <td>0.278349</td>\n","      <td>0.263831</td>\n","      <td>...</td>\n","      <td>0.557839</td>\n","      <td>0.478967</td>\n","      <td>0.429971</td>\n","      <td>0.426386</td>\n","      <td>0.431166</td>\n","      <td>0.470124</td>\n","      <td>0.462715</td>\n","      <td>0.472036</td>\n","      <td>0.475382</td>\n","      <td>0.494742</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-05 02:00:00</th>\n","      <td>0.124180</td>\n","      <td>0.149220</td>\n","      <td>0.202129</td>\n","      <td>0.258913</td>\n","      <td>0.314062</td>\n","      <td>0.385122</td>\n","      <td>0.443153</td>\n","      <td>0.403555</td>\n","      <td>0.310807</td>\n","      <td>0.278349</td>\n","      <td>...</td>\n","      <td>0.614245</td>\n","      <td>0.557839</td>\n","      <td>0.478967</td>\n","      <td>0.429971</td>\n","      <td>0.426386</td>\n","      <td>0.431166</td>\n","      <td>0.470124</td>\n","      <td>0.462715</td>\n","      <td>0.472036</td>\n","      <td>0.475382</td>\n","    </tr>\n","    <tr>\n","      <th>2010-10-05 03:00:00</th>\n","      <td>0.109828</td>\n","      <td>0.124180</td>\n","      <td>0.149220</td>\n","      <td>0.202129</td>\n","      <td>0.258913</td>\n","      <td>0.314062</td>\n","      <td>0.385122</td>\n","      <td>0.443153</td>\n","      <td>0.403555</td>\n","      <td>0.310807</td>\n","      <td>...</td>\n","      <td>0.642208</td>\n","      <td>0.614245</td>\n","      <td>0.557839</td>\n","      <td>0.478967</td>\n","      <td>0.429971</td>\n","      <td>0.426386</td>\n","      <td>0.431166</td>\n","      <td>0.470124</td>\n","      <td>0.462715</td>\n","      <td>0.472036</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>5 rows × 169 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2becf8c7-49fc-4b01-99f8-c56e71f094dc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2becf8c7-49fc-4b01-99f8-c56e71f094dc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2becf8c7-49fc-4b01-99f8-c56e71f094dc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["X_train_3D_enc, X_val_3D_enc, X_test_3D_enc = split_enc_data(data_df_scaled_reframed_enc,\n","                                                              START_TRAIN_DATE,\n","                                                              END_TRAIN_DATE,\n","                                                              START_VAL_DATE,\n","                                                              END_VAL_DATE,\n","                                                              START_TEST_DATE,\n","                                                              END_TEST_DATE,\n","                                                              STEPS_BACK_ENC)\n","\n","X_train_3D_dec, X_val_3D_dec, X_test_3D_dec= split_dec_data(data_df_scaled_reframed_dec,\n","                                                            START_TRAIN_DATE,\n","                                                            END_TRAIN_DATE,\n","                                                            START_VAL_DATE,\n","                                                            END_VAL_DATE,\n","                                                            START_TEST_DATE,\n","                                                            END_TEST_DATE,\n","                                                            STEPS_FORWARD,\n","                                                            LAST_STEP_BACK_DEC)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jus1PJoyaNfP","executionInfo":{"status":"ok","timestamp":1684953274260,"user_tz":-180,"elapsed":979,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"a6b98c47-e302-4383-9319-eff53f792793"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["(54697, 48, 8)\n","(8783, 48, 8)\n","(8737, 48, 8)\n","(54697, 72, 8)\n","(8783, 72, 8)\n","(8737, 72, 8)\n"]}]},{"cell_type":"code","source":["y_train = X_train_3D_dec[:, :LAST_STEP_FORWARD, TARGET_POS].copy()\n","X_train_3D_dec[:, :LAST_STEP_FORWARD, TARGET_POS] = 0\n","\n","y_val = X_val_3D_dec[:, :LAST_STEP_FORWARD, TARGET_POS].copy()\n","X_val_3D_dec[:, :LAST_STEP_FORWARD, TARGET_POS] = 0\n","\n","y_test = X_test_3D_dec[:, :LAST_STEP_FORWARD, TARGET_POS].copy()\n","X_test_3D_dec[:, :LAST_STEP_FORWARD, TARGET_POS] = 0"],"metadata":{"id":"zF9I2m8iomKK","executionInfo":{"status":"ok","timestamp":1684953274261,"user_tz":-180,"elapsed":3,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# X_train_3D_enc, X_val_3D_enc, X_test_3D_enc = np.flip(X_train_3D_enc, axis=1), np.flip(X_val_3D_enc, axis=1), np.flip(X_test_3D_enc, axis=1)\n","# X_train_3D_dec, X_val_3D_dec, X_test_3D_dec = np.flip(X_train_3D_dec, axis=1), np.flip(X_val_3D_dec, axis=1), np.flip(X_test_3D_dec, axis=1)"],"metadata":{"id":"67jGMKOobVPH","executionInfo":{"status":"ok","timestamp":1684953274261,"user_tz":-180,"elapsed":3,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["# *** DATALOADERS ***\n","train_dataset = LoadDataset(X_3D_enc=X_train_3D_enc.copy(), \n","                            X_3D_time_enc=X_train_3D_enc[:, :, TIME_POS].copy(),\n","                            X_3D_dec=X_train_3D_dec.copy(), \n","                            X_3D_time_dec=X_train_3D_dec[:, :, TIME_POS].copy(),\n","                            y=y_train)\n","train_dataloader = DataLoader(dataset=train_dataset, \n","                              batch_size=BATCH_SIZE,\n","                              shuffle=True)\n","\n","val_dataset = LoadDataset(X_3D_enc=X_val_3D_enc.copy(), \n","                          X_3D_time_enc=X_val_3D_enc[:, :, TIME_POS].copy(),\n","                          X_3D_dec=X_val_3D_dec.copy(), \n","                          X_3D_time_dec=X_val_3D_dec[:, :, TIME_POS].copy(),\n","                          y=y_val)\n","val_dataloader = DataLoader(dataset=val_dataset, \n","                            batch_size=BATCH_SIZE,\n","                            shuffle=False)"],"metadata":{"id":"eZaX-Utrp1Y9","executionInfo":{"status":"ok","timestamp":1684953275701,"user_tz":-180,"elapsed":1443,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["# TRAIN"],"metadata":{"id":"uPvm6Voxwk-r"}},{"cell_type":"code","source":["model = Informer(enc_in=8, dec_in=8, c_out=24, out_len=1, activation='gelu',\n","                 d_model=64, n_heads=8, e_layers=3, d_layers=2, d_ff=64, attn='prob').to(device)\n","\n","optimizer = torch.optim.Adam(params=model.parameters(),\n","                             lr=1e-3,\n","                             weight_decay=0)\n","# optimizer = t.optim.SGD(model.parameters(), lr=1e-3, momentum=0.9)\n","scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.33, patience=7, verbose=True)\n","loss_fn = MeanAbsolutePercentageError().to(device)   # MeanAbsolutePercentageError(), L1Loss(), MSELoss()\n","\n","!rm -rf \"model.pth\"\n","\n","model_results = train(model=model, \n","                      train_dataloader=train_dataloader,\n","                      val_dataloader=val_dataloader,\n","                      optimizer=optimizer,\n","                      scheduler=scheduler,\n","                      loss_fn=loss_fn,\n","                      epochs=100,\n","                      patience=10,\n","                      device=device,\n","                      path=PATH)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["e9fc812f2ad443c2af08b3b596f71475","997bd4055b8e41648ad328561592276b","cc7553b5f0664036990fc0e066a85597","e154c5f7658448a7aeba7ab29670c268","cb45d0cdf0204320a18ec79531e1f0b9","d79f7f46930c46a68c608180818f3985","3bce90f628c340fcbb70de1bdf5e227f","5edba41d60d64c61861d2948baafc4e4","c70d4541b13e44cd9abadddc6a4ad738","7f34575c2a2b4f6fb24e926c91224b2f","7d38a30c420f41e086a3fc590a6b44de"]},"id":"vPGP0lMEvtgT","executionInfo":{"status":"ok","timestamp":1684954122372,"user_tz":-180,"elapsed":839809,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"outputId":"653d4dd3-7013-4a91-d0bf-32b967eb62b2"},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/100 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9fc812f2ad443c2af08b3b596f71475"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: 1/100 | Loss: 0.5589 | Val loss: 10.9477 - *Checkpoint*\n","Epoch: 2/100 | Loss: 0.1942 | Val loss: 7.9181 - *Checkpoint*\n","Epoch: 3/100 | Loss: 0.1458 | Val loss: 5.8878 - *Checkpoint*\n","Epoch: 4/100 | Loss: 0.1308 | Val loss: 3.2738 - *Checkpoint*\n","Epoch: 5/100 | Loss: 0.1200 | Val loss: 1.8307 - *Checkpoint*\n","Epoch: 6/100 | Loss: 0.1207 | Val loss: 2.2558\n","Epoch: 7/100 | Loss: 0.1363 | Val loss: 3.4037\n","Epoch: 8/100 | Loss: 0.1286 | Val loss: 3.5361\n","Epoch 00009: reducing learning rate of group 0 to 3.3000e-04.\n","Epoch: 9/100 | Loss: 0.1177 | Val loss: 2.8345\n","Epoch: 10/100 | Loss: 0.1037 | Val loss: 2.6796\n","Epoch: 11/100 | Loss: 0.1010 | Val loss: 1.6663 - *Checkpoint*\n","Epoch: 12/100 | Loss: 0.0992 | Val loss: 2.1845\n","Epoch: 13/100 | Loss: 0.0994 | Val loss: 1.6307 - *Checkpoint*\n","Epoch: 14/100 | Loss: 0.0983 | Val loss: 3.1890\n","Epoch: 15/100 | Loss: 0.0982 | Val loss: 1.3358 - *Checkpoint*\n","Epoch: 16/100 | Loss: 0.0970 | Val loss: 2.2099\n","Epoch: 17/100 | Loss: 0.0967 | Val loss: 1.5319\n","Epoch: 18/100 | Loss: 0.0961 | Val loss: 2.0384\n","Epoch 00019: reducing learning rate of group 0 to 1.0890e-04.\n","Epoch: 19/100 | Loss: 0.0956 | Val loss: 1.6623\n","Epoch: 20/100 | Loss: 0.0939 | Val loss: 1.6715\n","Epoch: 21/100 | Loss: 0.0936 | Val loss: 1.6377\n","Epoch: 22/100 | Loss: 0.0931 | Val loss: 1.6841\n","Epoch: 23/100 | Loss: 0.0928 | Val loss: 1.3275 - *Checkpoint*\n","Epoch: 24/100 | Loss: 0.0925 | Val loss: 1.0515 - *Checkpoint*\n","Epoch: 25/100 | Loss: 0.0925 | Val loss: 1.3777\n","Epoch: 26/100 | Loss: 0.0922 | Val loss: 1.1002\n","Epoch: 27/100 | Loss: 0.0919 | Val loss: 1.5286\n","Epoch 00028: reducing learning rate of group 0 to 3.5937e-05.\n","Epoch: 28/100 | Loss: 0.0917 | Val loss: 1.1419\n","Epoch: 29/100 | Loss: 0.0914 | Val loss: 1.2161\n","Epoch: 30/100 | Loss: 0.0911 | Val loss: 1.2211\n","Epoch: 31/100 | Loss: 0.0910 | Val loss: 0.9639 - *Checkpoint*\n","Epoch: 32/100 | Loss: 0.0909 | Val loss: 1.3977\n","Epoch: 33/100 | Loss: 0.0907 | Val loss: 0.9182 - *Checkpoint*\n","Epoch: 34/100 | Loss: 0.0909 | Val loss: 2.1307\n","Epoch: 35/100 | Loss: 0.0908 | Val loss: 1.6846\n","Epoch: 36/100 | Loss: 0.0910 | Val loss: 1.4663\n","Epoch 00037: reducing learning rate of group 0 to 1.1859e-05.\n","Epoch: 37/100 | Loss: 0.0908 | Val loss: 1.0773\n","Epoch: 38/100 | Loss: 0.0903 | Val loss: 1.5897\n","Epoch: 39/100 | Loss: 0.0902 | Val loss: 0.9408\n","Epoch: 40/100 | Loss: 0.0904 | Val loss: 1.0844\n","Epoch: 41/100 | Loss: 0.0902 | Val loss: 0.9059 - *Checkpoint*\n","Epoch: 42/100 | Loss: 0.0903 | Val loss: 1.2835\n","Epoch: 43/100 | Loss: 0.0902 | Val loss: 1.9073\n","Epoch: 44/100 | Loss: 0.0905 | Val loss: 1.5186\n","Epoch 00045: reducing learning rate of group 0 to 3.9135e-06.\n","Epoch: 45/100 | Loss: 0.0902 | Val loss: 1.7327\n","Epoch: 46/100 | Loss: 0.0901 | Val loss: 1.0176\n","Epoch: 47/100 | Loss: 0.0899 | Val loss: 1.2478\n","Epoch: 48/100 | Loss: 0.0901 | Val loss: 1.1893\n","Epoch 00049: reducing learning rate of group 0 to 1.2915e-06.\n","Epoch: 49/100 | Loss: 0.0901 | Val loss: 1.7169\n","Epoch: 50/100 | Loss: 0.0901 | Val loss: 1.1545\n","Epoch: 51/100 | Loss: 0.0899 | Val loss: 1.2678\n","\n","Early stopping applied at epoch 51.\n"]}]},{"cell_type":"markdown","source":["# Inference + Post-Processing"],"metadata":{"id":"nM_LXxJxgRbH"}},{"cell_type":"code","source":["checkpoint = torch.load(\"model.pth\")\n","model.load_state_dict(checkpoint['model'])\n","optimizer.load_state_dict(checkpoint['optimizer'])\n","\n","X_enc = torch.tensor(X_test_3D_enc.copy(), dtype=torch.float32).to(device)\n","X_time_enc = torch.tensor(X_test_3D_enc[:, :, TIME_POS].copy(), dtype=torch.float32).to(device)\n","X_dec = torch.tensor(X_test_3D_dec.copy(), dtype=torch.float32).to(device)\n","X_time_dec = torch.tensor(X_test_3D_dec[:, :, TIME_POS].copy(), dtype=torch.float32).to(device)\n","\n","test_dataset = LoadDataset(X_3D_enc=X_enc, \n","                           X_3D_time_enc=X_time_enc,\n","                           X_3D_dec=X_dec, \n","                           X_3D_time_dec=X_time_dec,\n","                           y=y_test)\n","test_dataloader = DataLoader(dataset=test_dataset, \n","                             batch_size=BATCH_SIZE,\n","                             shuffle=False)\n","\n","model.eval()\n","with torch.inference_mode():\n","  for batch, (X_enc, X_time_enc, X_dec, X_time_dec, Y) in enumerate(test_dataloader):\n","    X_enc, X_time_enc, X_dec, X_time_dec, Y = X_enc.to(device), X_time_enc.to(device), X_dec.to(device), X_time_dec.to(device), Y.to(device)\n","    test_batch_preds = model(x_enc=X_enc, x_mark_enc=X_time_enc, x_dec=X_dec, x_mark_dec=X_time_dec).squeeze()\n","    if batch == 0:\n","      test_preds_scaled = test_batch_preds\n","    else:\n","      test_preds_scaled = torch.cat((test_preds_scaled, test_batch_preds), dim=0)\n","\n","print(test_preds_scaled.shape)"],"metadata":{"id":"PFvF3h-7cXg3","executionInfo":{"status":"ok","timestamp":1684954128009,"user_tz":-180,"elapsed":1953,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d171d83d-0239-4012-cd10-773f71696a1a"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-6-91a87307b89a>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.X_enc = torch.tensor(X_3D_enc, dtype=torch.float32)\n","<ipython-input-6-91a87307b89a>:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.X_time_enc = torch.tensor(X_3D_time_enc, dtype=torch.float32)\n","<ipython-input-6-91a87307b89a>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.X_dec = torch.tensor(X_3D_dec, dtype=torch.float32)\n","<ipython-input-6-91a87307b89a>:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  self.X_time_dec = torch.tensor(X_3D_time_dec, dtype=torch.float32)\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([8737, 24])\n"]}]},{"cell_type":"code","source":["test_preds_scaled = test_preds_scaled.cpu().numpy()\n","y_test_scaled = y_test.squeeze()\n","\n","test_preds = np.zeros(test_preds_scaled.shape)\n","for i in range(test_preds.shape[1]):\n","  test_preds[:, i] = scaler.data_min_[TARGET_POS] + test_preds_scaled[:, i] * (scaler.data_max_[TARGET_POS] - scaler.data_min_[TARGET_POS])\n","\n","y_test = np.zeros(y_test_scaled.shape)\n","for i in range(test_preds.shape[1]):\n","  y_test[:, i] = scaler.data_min_[TARGET_POS] + y_test_scaled[:, i] * (scaler.data_max_[TARGET_POS] - scaler.data_min_[TARGET_POS])"],"metadata":{"id":"-Ur5QzSDNzq2","executionInfo":{"status":"ok","timestamp":1684954128010,"user_tz":-180,"elapsed":3,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["mape_list = list()\n","step_results_dict = {}\n","for step in range(STEPS_FORWARD):\n","  step_results_df = pd.DataFrame(\n","      {\n","          \"real\": y_test[:, step],\n","          \"predictions\": test_preds[:, step]\n","      }\n","  )\n","  step_results_df['abs_error'] = abs(step_results_df['real'] - step_results_df['predictions'])\n","  step_results_df['ape'] = np.where(step_results_df['real'] == 0, np.NaN, 100 * step_results_df['abs_error']/step_results_df['real'])\n","  step_mape = step_results_df['ape'].mean()\n","  mape_list.append(step_mape)\n","  print(f\"Step {step} -> MAPE = {step_mape}\")\n","\n","  step_results_dict[step] = step_results_df\n","mape = np.array(mape_list).mean()\n","print(f\"\\nMAPE = {mape}\")"],"metadata":{"id":"EJSskMCYKBb5","executionInfo":{"status":"ok","timestamp":1684954128010,"user_tz":-180,"elapsed":3,"user":{"displayName":"Achil Pal","userId":"04608072963754583562"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c33a7fdb-fdc3-40a8-929f-d4161e56ad7c"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Step 0 -> MAPE = 5.250920526996415\n","Step 1 -> MAPE = 5.090428547623404\n","Step 2 -> MAPE = 5.079517852429103\n","Step 3 -> MAPE = 5.130401203721126\n","Step 4 -> MAPE = 5.112877857286394\n","Step 5 -> MAPE = 5.339500039811258\n","Step 6 -> MAPE = 5.1691477907448515\n","Step 7 -> MAPE = 5.192916046774165\n","Step 8 -> MAPE = 5.01147231288138\n","Step 9 -> MAPE = 5.000739743006105\n","Step 10 -> MAPE = 4.901129019630552\n","Step 11 -> MAPE = 5.063385515064333\n","Step 12 -> MAPE = 4.976881684386488\n","Step 13 -> MAPE = 5.134460759590952\n","Step 14 -> MAPE = 5.060965959824726\n","Step 15 -> MAPE = 4.906603001715368\n","Step 16 -> MAPE = 4.934840910566509\n","Step 17 -> MAPE = 4.905535460983227\n","Step 18 -> MAPE = 4.962147129925232\n","Step 19 -> MAPE = 4.960518610391143\n","Step 20 -> MAPE = 4.81822777724318\n","Step 21 -> MAPE = 4.851655151923843\n","Step 22 -> MAPE = 4.9351507636474885\n","Step 23 -> MAPE = 4.775955792439734\n","\n","MAPE = 5.023557477441957\n"]}]}]}